{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6NlqNiDSjOb4"
      },
      "outputs": [],
      "source": [
        "#!pip install tensorflow\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.datasets.mnist as mnist\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.optimizers import SGD\n",
        "import random\n",
        "from keras.callbacks import EarlyStopping\n",
        "import math\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxHm7sIWj6uA"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0Hs0MWLi8kM",
        "outputId": "91fda3e0-de37-4b42-e294-7641f5d40c9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Training images shape: (60000, 28, 28)\n",
            "Training labels shape: (60000,)\n",
            "Testing images shape: (10000, 28, 28)\n",
            "Testing labels shape: (10000,)\n"
          ]
        }
      ],
      "source": [
        "# Load MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Shape of the training and testing data\n",
        "print(\"Training images shape:\", train_images.shape)\n",
        "print(\"Training labels shape:\", train_labels.shape)\n",
        "print(\"Testing images shape:\", test_images.shape)\n",
        "print(\"Testing labels shape:\", test_labels.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "znNjl2lNoM9v"
      },
      "outputs": [],
      "source": [
        "# Normalize the pixel values to be between 0 and 1\n",
        "train_images = train_images.astype('float32') / 255\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "\n",
        "# One-hot encode the labels\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TSoNu6L-jO2m"
      },
      "outputs": [],
      "source": [
        "def create_model(num_parameters, train_images, train_labels):\n",
        "    if not isinstance(num_parameters, int) or num_parameters <= 0:\n",
        "        raise ValueError(\"num_parameters must be a positive integer.\")\n",
        "\n",
        "    model = Sequential([\n",
        "        Flatten(input_shape=(28, 28)),  # Flatten the input images\n",
        "        Dense(num_parameters, activation='relu'),   # Fully connected layer with num_parameters neurons\\renewcommand{\\thesection}{Appendix \\Alph{section}}\n",
        "        Dense(10, activation='softmax')  # Output layer with 10 neurons (one for each class)\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "#    model.compile(optimizer='adam',\n",
        "#                  loss='categorical_crossentropy',\n",
        "#                  metrics=['accuracy'])\n",
        "\n",
        "    # Compile the model\n",
        "    #model.compile(optimizer='adam',\n",
        "    #                loss='categorical_crossentropy',\n",
        "    #                metrics=['accuracy'])\n",
        "    sgd = SGD(momentum=0.95)\n",
        "    model.compile(optimizer=sgd,\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Fit the model and store the training history\n",
        "    history = model.fit(train_images, train_labels, epochs=50, batch_size=64, validation_split=0.2)\n",
        "\n",
        "    # Extract the training and validation error from the history\n",
        "    train_error = history.history['loss'][-1]  # Training error is the final loss value\n",
        "    val_error = history.history['val_loss'][-1]  # Validation error is the final validation loss value\n",
        "\n",
        "    return train_error, val_error, model.count_params()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cjQNv3yH_QIF"
      },
      "outputs": [],
      "source": [
        "# JEFF STINKING UP THE PLACE\n",
        "# repeat of above cell, but with 4000 images (aligned with double-descent paper)\n",
        "train_images = train_images[:4000]\n",
        "train_labels = train_labels[:4000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "M7B067bvjfha"
      },
      "outputs": [],
      "source": [
        "def get_num_hidden(n):\n",
        "  # gives an approximation of the number of hidden layers for a desired number of parameters (n)\n",
        "    return (n - 10) / (785 + 10 + 1)\n",
        "\n",
        "#params = [2**i for i in range(2,8)] # these are number of units in the hidden layer\n",
        "#params = [4, 8, 16, 32, 33, 34, 35, 40, 45, 49, 50, 51, 52, 55, 60, 64, 128] # JEFF STINKING UP THE PLACE\n",
        "#params = [4, 8, 16, 32] + list(range(40, 60)) + [64, 128]\n",
        "\n",
        "interpolation_threshold = len(train_images) * 10\n",
        "interp_thresh_H = round(get_num_hidden(interpolation_threshold))\n",
        "params = [4, 8, 16, 32] + list(range(interp_thresh_H-8, interp_thresh_H+8, 2)) + [64,76, 88, 100]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZVS7DZUjqXa",
        "outputId": "9f661c3f-17fa-409c-f3d5-a6cdc16c6e56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.1857 - loss: 2.1357 - val_accuracy: 0.4625 - val_loss: 1.5922\n",
            "Epoch 2/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5414 - loss: 1.3857 - val_accuracy: 0.6413 - val_loss: 1.0171\n",
            "Epoch 3/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6796 - loss: 0.9554 - val_accuracy: 0.7163 - val_loss: 0.8110\n",
            "Epoch 4/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7549 - loss: 0.7682 - val_accuracy: 0.7312 - val_loss: 0.7442\n",
            "Epoch 5/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7769 - loss: 0.7155 - val_accuracy: 0.7688 - val_loss: 0.6851\n",
            "Epoch 6/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8103 - loss: 0.5984 - val_accuracy: 0.7750 - val_loss: 0.6681\n",
            "Epoch 7/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8084 - loss: 0.6021 - val_accuracy: 0.7700 - val_loss: 0.6685\n",
            "Epoch 8/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8256 - loss: 0.5679 - val_accuracy: 0.7837 - val_loss: 0.6721\n",
            "Epoch 9/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8199 - loss: 0.5788 - val_accuracy: 0.7763 - val_loss: 0.6880\n",
            "Epoch 10/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8318 - loss: 0.5683 - val_accuracy: 0.7937 - val_loss: 0.6457\n",
            "Epoch 11/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8257 - loss: 0.5422 - val_accuracy: 0.7950 - val_loss: 0.6316\n",
            "Epoch 12/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8337 - loss: 0.5290 - val_accuracy: 0.7900 - val_loss: 0.6211\n",
            "Epoch 13/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8440 - loss: 0.5101 - val_accuracy: 0.7975 - val_loss: 0.6312\n",
            "Epoch 14/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8392 - loss: 0.5188 - val_accuracy: 0.7850 - val_loss: 0.6394\n",
            "Epoch 15/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8403 - loss: 0.5033 - val_accuracy: 0.7912 - val_loss: 0.6386\n",
            "Epoch 16/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8626 - loss: 0.4598 - val_accuracy: 0.7987 - val_loss: 0.6370\n",
            "Epoch 17/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8594 - loss: 0.4535 - val_accuracy: 0.7962 - val_loss: 0.6360\n",
            "Epoch 18/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8484 - loss: 0.4685 - val_accuracy: 0.7725 - val_loss: 0.6393\n",
            "Epoch 19/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8526 - loss: 0.4573 - val_accuracy: 0.7900 - val_loss: 0.6271\n",
            "Epoch 20/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8626 - loss: 0.4631 - val_accuracy: 0.7875 - val_loss: 0.6489\n",
            "Epoch 21/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8561 - loss: 0.4789 - val_accuracy: 0.7937 - val_loss: 0.6223\n",
            "Epoch 22/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8686 - loss: 0.4346 - val_accuracy: 0.7975 - val_loss: 0.6312\n",
            "Epoch 23/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8676 - loss: 0.4432 - val_accuracy: 0.7975 - val_loss: 0.6356\n",
            "Epoch 24/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8646 - loss: 0.4253 - val_accuracy: 0.7900 - val_loss: 0.6776\n",
            "Epoch 25/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8582 - loss: 0.4473 - val_accuracy: 0.7975 - val_loss: 0.6321\n",
            "Epoch 26/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8533 - loss: 0.4525 - val_accuracy: 0.7725 - val_loss: 0.6682\n",
            "Epoch 27/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8690 - loss: 0.4211 - val_accuracy: 0.7900 - val_loss: 0.6662\n",
            "Epoch 28/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8679 - loss: 0.4239 - val_accuracy: 0.7862 - val_loss: 0.6644\n",
            "Epoch 29/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8777 - loss: 0.4045 - val_accuracy: 0.7887 - val_loss: 0.6345\n",
            "Epoch 30/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8730 - loss: 0.4149 - val_accuracy: 0.7875 - val_loss: 0.6431\n",
            "Epoch 31/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8705 - loss: 0.3938 - val_accuracy: 0.7925 - val_loss: 0.6344\n",
            "Epoch 32/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8819 - loss: 0.4049 - val_accuracy: 0.7850 - val_loss: 0.6517\n",
            "Epoch 33/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8675 - loss: 0.4242 - val_accuracy: 0.7788 - val_loss: 0.6983\n",
            "Epoch 34/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8767 - loss: 0.3966 - val_accuracy: 0.7875 - val_loss: 0.6435\n",
            "Epoch 35/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8875 - loss: 0.3915 - val_accuracy: 0.7887 - val_loss: 0.6553\n",
            "Epoch 36/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8856 - loss: 0.3814 - val_accuracy: 0.7950 - val_loss: 0.6447\n",
            "Epoch 37/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8812 - loss: 0.3898 - val_accuracy: 0.7925 - val_loss: 0.6597\n",
            "Epoch 38/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8830 - loss: 0.3975 - val_accuracy: 0.7825 - val_loss: 0.6647\n",
            "Epoch 39/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8898 - loss: 0.3759 - val_accuracy: 0.7925 - val_loss: 0.6913\n",
            "Epoch 40/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8821 - loss: 0.3940 - val_accuracy: 0.7937 - val_loss: 0.6293\n",
            "Epoch 41/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8977 - loss: 0.3548 - val_accuracy: 0.8012 - val_loss: 0.6431\n",
            "Epoch 42/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8825 - loss: 0.3838 - val_accuracy: 0.8075 - val_loss: 0.6447\n",
            "Epoch 43/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8954 - loss: 0.3549 - val_accuracy: 0.7812 - val_loss: 0.6636\n",
            "Epoch 44/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8931 - loss: 0.3520 - val_accuracy: 0.7900 - val_loss: 0.6587\n",
            "Epoch 45/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8900 - loss: 0.3621 - val_accuracy: 0.7937 - val_loss: 0.6729\n",
            "Epoch 46/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8996 - loss: 0.3387 - val_accuracy: 0.7950 - val_loss: 0.6574\n",
            "Epoch 47/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8777 - loss: 0.3746 - val_accuracy: 0.7950 - val_loss: 0.6525\n",
            "Epoch 48/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8743 - loss: 0.3860 - val_accuracy: 0.7962 - val_loss: 0.6660\n",
            "Epoch 49/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8920 - loss: 0.3733 - val_accuracy: 0.7987 - val_loss: 0.6642\n",
            "Epoch 50/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8915 - loss: 0.3447 - val_accuracy: 0.7950 - val_loss: 0.6791\n",
            "Epoch 1/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.2414 - loss: 2.1073 - val_accuracy: 0.6687 - val_loss: 1.1533\n",
            "Epoch 2/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7125 - loss: 0.9515 - val_accuracy: 0.8075 - val_loss: 0.6321\n",
            "Epoch 3/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8293 - loss: 0.5676 - val_accuracy: 0.8450 - val_loss: 0.5319\n",
            "Epoch 4/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8521 - loss: 0.4824 - val_accuracy: 0.8737 - val_loss: 0.4680\n",
            "Epoch 5/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8803 - loss: 0.4013 - val_accuracy: 0.8650 - val_loss: 0.4772\n",
            "Epoch 6/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9093 - loss: 0.3307 - val_accuracy: 0.8662 - val_loss: 0.4605\n",
            "Epoch 7/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9057 - loss: 0.3163 - val_accuracy: 0.8875 - val_loss: 0.4246\n",
            "Epoch 8/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9183 - loss: 0.2986 - val_accuracy: 0.8750 - val_loss: 0.4456\n",
            "Epoch 9/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9162 - loss: 0.2870 - val_accuracy: 0.8838 - val_loss: 0.4306\n",
            "Epoch 10/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9256 - loss: 0.2856 - val_accuracy: 0.8913 - val_loss: 0.4230\n",
            "Epoch 11/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9235 - loss: 0.2680 - val_accuracy: 0.8838 - val_loss: 0.4325\n",
            "Epoch 12/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9326 - loss: 0.2391 - val_accuracy: 0.8813 - val_loss: 0.4266\n",
            "Epoch 13/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9355 - loss: 0.2318 - val_accuracy: 0.8850 - val_loss: 0.4325\n",
            "Epoch 14/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9437 - loss: 0.2167 - val_accuracy: 0.8788 - val_loss: 0.4389\n",
            "Epoch 15/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9453 - loss: 0.2150 - val_accuracy: 0.8712 - val_loss: 0.4507\n",
            "Epoch 16/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9423 - loss: 0.2029 - val_accuracy: 0.8788 - val_loss: 0.4441\n",
            "Epoch 17/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9421 - loss: 0.2092 - val_accuracy: 0.8750 - val_loss: 0.4394\n",
            "Epoch 18/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9519 - loss: 0.1822 - val_accuracy: 0.8838 - val_loss: 0.4428\n",
            "Epoch 19/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9498 - loss: 0.1893 - val_accuracy: 0.8775 - val_loss: 0.4520\n",
            "Epoch 20/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9521 - loss: 0.1784 - val_accuracy: 0.8775 - val_loss: 0.4447\n",
            "Epoch 21/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9512 - loss: 0.1809 - val_accuracy: 0.8737 - val_loss: 0.4740\n",
            "Epoch 22/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9564 - loss: 0.1684 - val_accuracy: 0.8737 - val_loss: 0.4761\n",
            "Epoch 23/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9559 - loss: 0.1606 - val_accuracy: 0.8788 - val_loss: 0.4642\n",
            "Epoch 24/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9596 - loss: 0.1567 - val_accuracy: 0.8800 - val_loss: 0.4690\n",
            "Epoch 25/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9644 - loss: 0.1438 - val_accuracy: 0.8725 - val_loss: 0.4780\n",
            "Epoch 26/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9605 - loss: 0.1472 - val_accuracy: 0.8788 - val_loss: 0.4703\n",
            "Epoch 27/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9664 - loss: 0.1313 - val_accuracy: 0.8662 - val_loss: 0.4922\n",
            "Epoch 28/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9657 - loss: 0.1343 - val_accuracy: 0.8725 - val_loss: 0.4974\n",
            "Epoch 29/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9738 - loss: 0.1105 - val_accuracy: 0.8750 - val_loss: 0.4990\n",
            "Epoch 30/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9745 - loss: 0.1254 - val_accuracy: 0.8775 - val_loss: 0.5076\n",
            "Epoch 31/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9634 - loss: 0.1401 - val_accuracy: 0.8788 - val_loss: 0.4984\n",
            "Epoch 32/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9758 - loss: 0.1102 - val_accuracy: 0.8788 - val_loss: 0.5123\n",
            "Epoch 33/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9725 - loss: 0.1132 - val_accuracy: 0.8637 - val_loss: 0.5238\n",
            "Epoch 34/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9710 - loss: 0.1102 - val_accuracy: 0.8775 - val_loss: 0.5151\n",
            "Epoch 35/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9743 - loss: 0.1090 - val_accuracy: 0.8737 - val_loss: 0.5348\n",
            "Epoch 36/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9705 - loss: 0.1046 - val_accuracy: 0.8737 - val_loss: 0.5293\n",
            "Epoch 37/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9758 - loss: 0.0952 - val_accuracy: 0.8675 - val_loss: 0.5349\n",
            "Epoch 38/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9818 - loss: 0.0870 - val_accuracy: 0.8725 - val_loss: 0.5317\n",
            "Epoch 39/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9817 - loss: 0.0869 - val_accuracy: 0.8675 - val_loss: 0.5525\n",
            "Epoch 40/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9778 - loss: 0.0868 - val_accuracy: 0.8637 - val_loss: 0.5446\n",
            "Epoch 41/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9764 - loss: 0.0862 - val_accuracy: 0.8662 - val_loss: 0.5719\n",
            "Epoch 42/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9837 - loss: 0.0859 - val_accuracy: 0.8712 - val_loss: 0.5655\n",
            "Epoch 43/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9833 - loss: 0.0808 - val_accuracy: 0.8750 - val_loss: 0.5489\n",
            "Epoch 44/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9817 - loss: 0.0747 - val_accuracy: 0.8700 - val_loss: 0.5683\n",
            "Epoch 45/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9841 - loss: 0.0747 - val_accuracy: 0.8637 - val_loss: 0.5804\n",
            "Epoch 46/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9872 - loss: 0.0687 - val_accuracy: 0.8687 - val_loss: 0.5986\n",
            "Epoch 47/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9858 - loss: 0.0672 - val_accuracy: 0.8675 - val_loss: 0.6062\n",
            "Epoch 48/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9852 - loss: 0.0681 - val_accuracy: 0.8712 - val_loss: 0.5971\n",
            "Epoch 49/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9862 - loss: 0.0706 - val_accuracy: 0.8675 - val_loss: 0.6193\n",
            "Epoch 50/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9923 - loss: 0.0553 - val_accuracy: 0.8675 - val_loss: 0.6194\n",
            "Epoch 1/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.2810 - loss: 1.9715 - val_accuracy: 0.7650 - val_loss: 0.8582\n",
            "Epoch 2/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8304 - loss: 0.6418 - val_accuracy: 0.8737 - val_loss: 0.4709\n",
            "Epoch 3/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8760 - loss: 0.4156 - val_accuracy: 0.8813 - val_loss: 0.4235\n",
            "Epoch 4/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9053 - loss: 0.3316 - val_accuracy: 0.8950 - val_loss: 0.3672\n",
            "Epoch 5/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9275 - loss: 0.2883 - val_accuracy: 0.9062 - val_loss: 0.3426\n",
            "Epoch 6/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9271 - loss: 0.2551 - val_accuracy: 0.9125 - val_loss: 0.3172\n",
            "Epoch 7/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9323 - loss: 0.2364 - val_accuracy: 0.9062 - val_loss: 0.3153\n",
            "Epoch 8/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9396 - loss: 0.2287 - val_accuracy: 0.9100 - val_loss: 0.3320\n",
            "Epoch 9/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9313 - loss: 0.2224 - val_accuracy: 0.9125 - val_loss: 0.3073\n",
            "Epoch 10/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9506 - loss: 0.1747 - val_accuracy: 0.9075 - val_loss: 0.3383\n",
            "Epoch 11/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9523 - loss: 0.1768 - val_accuracy: 0.9200 - val_loss: 0.3046\n",
            "Epoch 12/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9584 - loss: 0.1589 - val_accuracy: 0.9050 - val_loss: 0.3175\n",
            "Epoch 13/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9654 - loss: 0.1336 - val_accuracy: 0.9162 - val_loss: 0.3115\n",
            "Epoch 14/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9644 - loss: 0.1371 - val_accuracy: 0.9000 - val_loss: 0.3433\n",
            "Epoch 15/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9645 - loss: 0.1233 - val_accuracy: 0.9175 - val_loss: 0.3039\n",
            "Epoch 16/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9724 - loss: 0.1286 - val_accuracy: 0.9150 - val_loss: 0.3061\n",
            "Epoch 17/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9729 - loss: 0.1088 - val_accuracy: 0.9112 - val_loss: 0.3212\n",
            "Epoch 18/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9764 - loss: 0.1110 - val_accuracy: 0.9150 - val_loss: 0.3124\n",
            "Epoch 19/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9779 - loss: 0.0991 - val_accuracy: 0.9038 - val_loss: 0.3356\n",
            "Epoch 20/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9812 - loss: 0.0858 - val_accuracy: 0.9038 - val_loss: 0.3184\n",
            "Epoch 21/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9810 - loss: 0.0913 - val_accuracy: 0.9087 - val_loss: 0.3523\n",
            "Epoch 22/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9850 - loss: 0.0744 - val_accuracy: 0.9075 - val_loss: 0.3317\n",
            "Epoch 23/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9877 - loss: 0.0678 - val_accuracy: 0.9050 - val_loss: 0.3581\n",
            "Epoch 24/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9871 - loss: 0.0753 - val_accuracy: 0.9062 - val_loss: 0.3324\n",
            "Epoch 25/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9882 - loss: 0.0750 - val_accuracy: 0.9100 - val_loss: 0.3310\n",
            "Epoch 26/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9889 - loss: 0.0582 - val_accuracy: 0.9025 - val_loss: 0.3404\n",
            "Epoch 27/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9866 - loss: 0.0747 - val_accuracy: 0.9100 - val_loss: 0.3563\n",
            "Epoch 28/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9918 - loss: 0.0577 - val_accuracy: 0.9125 - val_loss: 0.3415\n",
            "Epoch 29/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9934 - loss: 0.0525 - val_accuracy: 0.9000 - val_loss: 0.3852\n",
            "Epoch 30/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9904 - loss: 0.0606 - val_accuracy: 0.9025 - val_loss: 0.3769\n",
            "Epoch 31/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9914 - loss: 0.0493 - val_accuracy: 0.9025 - val_loss: 0.3548\n",
            "Epoch 32/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9931 - loss: 0.0482 - val_accuracy: 0.9000 - val_loss: 0.3666\n",
            "Epoch 33/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9958 - loss: 0.0431 - val_accuracy: 0.9038 - val_loss: 0.3725\n",
            "Epoch 34/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9955 - loss: 0.0424 - val_accuracy: 0.9087 - val_loss: 0.3716\n",
            "Epoch 35/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9924 - loss: 0.0477 - val_accuracy: 0.9013 - val_loss: 0.3759\n",
            "Epoch 36/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9977 - loss: 0.0392 - val_accuracy: 0.9000 - val_loss: 0.3707\n",
            "Epoch 37/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9955 - loss: 0.0377 - val_accuracy: 0.9025 - val_loss: 0.3853\n",
            "Epoch 38/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9956 - loss: 0.0436 - val_accuracy: 0.8988 - val_loss: 0.3765\n",
            "Epoch 39/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9966 - loss: 0.0323 - val_accuracy: 0.9013 - val_loss: 0.3857\n",
            "Epoch 40/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9959 - loss: 0.0343 - val_accuracy: 0.8988 - val_loss: 0.3902\n",
            "Epoch 41/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9964 - loss: 0.0303 - val_accuracy: 0.9038 - val_loss: 0.4060\n",
            "Epoch 42/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9981 - loss: 0.0299 - val_accuracy: 0.9013 - val_loss: 0.3914\n",
            "Epoch 43/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9986 - loss: 0.0230 - val_accuracy: 0.9038 - val_loss: 0.4083\n",
            "Epoch 44/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9976 - loss: 0.0317 - val_accuracy: 0.9075 - val_loss: 0.4080\n",
            "Epoch 45/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9981 - loss: 0.0271 - val_accuracy: 0.9000 - val_loss: 0.4269\n",
            "Epoch 46/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0229 - val_accuracy: 0.8988 - val_loss: 0.4046\n",
            "Epoch 47/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0211 - val_accuracy: 0.8988 - val_loss: 0.4127\n",
            "Epoch 48/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0220 - val_accuracy: 0.9025 - val_loss: 0.4253\n",
            "Epoch 49/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9971 - loss: 0.0278 - val_accuracy: 0.8988 - val_loss: 0.4289\n",
            "Epoch 50/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0221 - val_accuracy: 0.9013 - val_loss: 0.4167\n",
            "Epoch 1/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.3763 - loss: 1.8822 - val_accuracy: 0.8000 - val_loss: 0.6242\n",
            "Epoch 2/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8359 - loss: 0.5289 - val_accuracy: 0.8850 - val_loss: 0.4284\n",
            "Epoch 3/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8857 - loss: 0.3832 - val_accuracy: 0.8875 - val_loss: 0.4007\n",
            "Epoch 4/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9071 - loss: 0.3043 - val_accuracy: 0.9050 - val_loss: 0.3373\n",
            "Epoch 5/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9289 - loss: 0.2581 - val_accuracy: 0.8938 - val_loss: 0.3574\n",
            "Epoch 6/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9322 - loss: 0.2486 - val_accuracy: 0.8988 - val_loss: 0.3554\n",
            "Epoch 7/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9433 - loss: 0.1998 - val_accuracy: 0.9112 - val_loss: 0.3106\n",
            "Epoch 8/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9321 - loss: 0.2078 - val_accuracy: 0.9175 - val_loss: 0.2912\n",
            "Epoch 9/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9512 - loss: 0.1795 - val_accuracy: 0.9137 - val_loss: 0.3018\n",
            "Epoch 10/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9553 - loss: 0.1640 - val_accuracy: 0.9125 - val_loss: 0.2999\n",
            "Epoch 11/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9599 - loss: 0.1454 - val_accuracy: 0.9125 - val_loss: 0.2975\n",
            "Epoch 12/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9626 - loss: 0.1220 - val_accuracy: 0.9175 - val_loss: 0.2996\n",
            "Epoch 13/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9653 - loss: 0.1273 - val_accuracy: 0.9187 - val_loss: 0.2962\n",
            "Epoch 14/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9798 - loss: 0.0974 - val_accuracy: 0.9162 - val_loss: 0.2864\n",
            "Epoch 15/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9783 - loss: 0.0947 - val_accuracy: 0.9187 - val_loss: 0.3065\n",
            "Epoch 16/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9740 - loss: 0.1024 - val_accuracy: 0.9200 - val_loss: 0.2969\n",
            "Epoch 17/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9770 - loss: 0.0896 - val_accuracy: 0.9187 - val_loss: 0.2902\n",
            "Epoch 18/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9880 - loss: 0.0700 - val_accuracy: 0.9137 - val_loss: 0.3175\n",
            "Epoch 19/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9882 - loss: 0.0757 - val_accuracy: 0.9137 - val_loss: 0.3098\n",
            "Epoch 20/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9865 - loss: 0.0629 - val_accuracy: 0.9175 - val_loss: 0.3039\n",
            "Epoch 21/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9910 - loss: 0.0634 - val_accuracy: 0.9137 - val_loss: 0.3185\n",
            "Epoch 22/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9906 - loss: 0.0551 - val_accuracy: 0.9087 - val_loss: 0.3071\n",
            "Epoch 23/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9923 - loss: 0.0524 - val_accuracy: 0.9112 - val_loss: 0.3227\n",
            "Epoch 24/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9896 - loss: 0.0494 - val_accuracy: 0.9137 - val_loss: 0.3200\n",
            "Epoch 25/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9942 - loss: 0.0435 - val_accuracy: 0.9137 - val_loss: 0.3132\n",
            "Epoch 26/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9964 - loss: 0.0359 - val_accuracy: 0.9112 - val_loss: 0.3242\n",
            "Epoch 27/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9963 - loss: 0.0365 - val_accuracy: 0.9100 - val_loss: 0.3246\n",
            "Epoch 28/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9967 - loss: 0.0368 - val_accuracy: 0.9112 - val_loss: 0.3197\n",
            "Epoch 29/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0329 - val_accuracy: 0.9175 - val_loss: 0.3229\n",
            "Epoch 30/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9987 - loss: 0.0280 - val_accuracy: 0.9112 - val_loss: 0.3342\n",
            "Epoch 31/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9984 - loss: 0.0302 - val_accuracy: 0.9150 - val_loss: 0.3264\n",
            "Epoch 32/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9986 - loss: 0.0303 - val_accuracy: 0.9112 - val_loss: 0.3311\n",
            "Epoch 33/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0248 - val_accuracy: 0.9125 - val_loss: 0.3295\n",
            "Epoch 34/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0236 - val_accuracy: 0.9125 - val_loss: 0.3323\n",
            "Epoch 35/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0217 - val_accuracy: 0.9150 - val_loss: 0.3348\n",
            "Epoch 36/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0206 - val_accuracy: 0.9087 - val_loss: 0.3367\n",
            "Epoch 37/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 0.0199 - val_accuracy: 0.9100 - val_loss: 0.3406\n",
            "Epoch 38/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0186 - val_accuracy: 0.9075 - val_loss: 0.3429\n",
            "Epoch 39/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0185 - val_accuracy: 0.9112 - val_loss: 0.3442\n",
            "Epoch 40/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0162 - val_accuracy: 0.9125 - val_loss: 0.3466\n",
            "Epoch 41/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0167 - val_accuracy: 0.9125 - val_loss: 0.3474\n",
            "Epoch 42/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0158 - val_accuracy: 0.9100 - val_loss: 0.3515\n",
            "Epoch 43/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0151 - val_accuracy: 0.9125 - val_loss: 0.3502\n",
            "Epoch 44/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0133 - val_accuracy: 0.9112 - val_loss: 0.3519\n",
            "Epoch 45/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0130 - val_accuracy: 0.9087 - val_loss: 0.3557\n",
            "Epoch 46/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0124 - val_accuracy: 0.9112 - val_loss: 0.3541\n",
            "Epoch 47/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0126 - val_accuracy: 0.9137 - val_loss: 0.3604\n",
            "Epoch 48/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0108 - val_accuracy: 0.9125 - val_loss: 0.3577\n",
            "Epoch 49/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0118 - val_accuracy: 0.9112 - val_loss: 0.3631\n",
            "Epoch 50/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0108 - val_accuracy: 0.9125 - val_loss: 0.3622\n",
            "Epoch 1/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.4324 - loss: 1.8781 - val_accuracy: 0.8338 - val_loss: 0.5905\n",
            "Epoch 2/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8535 - loss: 0.4897 - val_accuracy: 0.8775 - val_loss: 0.4137\n",
            "Epoch 3/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9024 - loss: 0.3493 - val_accuracy: 0.8988 - val_loss: 0.3585\n",
            "Epoch 4/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9232 - loss: 0.2737 - val_accuracy: 0.9062 - val_loss: 0.3225\n",
            "Epoch 5/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9391 - loss: 0.2359 - val_accuracy: 0.9162 - val_loss: 0.3130\n",
            "Epoch 6/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9504 - loss: 0.2014 - val_accuracy: 0.9062 - val_loss: 0.3183\n",
            "Epoch 7/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9462 - loss: 0.1933 - val_accuracy: 0.9075 - val_loss: 0.3124\n",
            "Epoch 8/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9501 - loss: 0.1826 - val_accuracy: 0.9137 - val_loss: 0.2919\n",
            "Epoch 9/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9619 - loss: 0.1637 - val_accuracy: 0.9162 - val_loss: 0.2959\n",
            "Epoch 10/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9584 - loss: 0.1556 - val_accuracy: 0.9237 - val_loss: 0.2794\n",
            "Epoch 11/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9674 - loss: 0.1286 - val_accuracy: 0.9150 - val_loss: 0.2969\n",
            "Epoch 12/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9678 - loss: 0.1292 - val_accuracy: 0.9212 - val_loss: 0.2752\n",
            "Epoch 13/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9771 - loss: 0.1084 - val_accuracy: 0.9112 - val_loss: 0.2985\n",
            "Epoch 14/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9776 - loss: 0.0975 - val_accuracy: 0.9100 - val_loss: 0.2997\n",
            "Epoch 15/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9802 - loss: 0.0921 - val_accuracy: 0.9225 - val_loss: 0.2846\n",
            "Epoch 16/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9808 - loss: 0.0801 - val_accuracy: 0.9225 - val_loss: 0.2893\n",
            "Epoch 17/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9855 - loss: 0.0784 - val_accuracy: 0.9187 - val_loss: 0.2882\n",
            "Epoch 18/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9844 - loss: 0.0749 - val_accuracy: 0.9225 - val_loss: 0.2880\n",
            "Epoch 19/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9872 - loss: 0.0638 - val_accuracy: 0.9225 - val_loss: 0.2909\n",
            "Epoch 20/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9940 - loss: 0.0535 - val_accuracy: 0.9175 - val_loss: 0.2982\n",
            "Epoch 21/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9900 - loss: 0.0534 - val_accuracy: 0.9250 - val_loss: 0.2919\n",
            "Epoch 22/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9910 - loss: 0.0518 - val_accuracy: 0.9212 - val_loss: 0.3052\n",
            "Epoch 23/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9947 - loss: 0.0472 - val_accuracy: 0.9200 - val_loss: 0.3011\n",
            "Epoch 24/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9934 - loss: 0.0484 - val_accuracy: 0.9200 - val_loss: 0.3053\n",
            "Epoch 25/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9955 - loss: 0.0414 - val_accuracy: 0.9187 - val_loss: 0.3125\n",
            "Epoch 26/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9956 - loss: 0.0436 - val_accuracy: 0.9175 - val_loss: 0.3017\n",
            "Epoch 27/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9984 - loss: 0.0386 - val_accuracy: 0.9225 - val_loss: 0.3121\n",
            "Epoch 28/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9955 - loss: 0.0360 - val_accuracy: 0.9200 - val_loss: 0.3057\n",
            "Epoch 29/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9966 - loss: 0.0363 - val_accuracy: 0.9200 - val_loss: 0.3170\n",
            "Epoch 30/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9980 - loss: 0.0306 - val_accuracy: 0.9200 - val_loss: 0.3226\n",
            "Epoch 31/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0272 - val_accuracy: 0.9212 - val_loss: 0.3215\n",
            "Epoch 32/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9984 - loss: 0.0269 - val_accuracy: 0.9212 - val_loss: 0.3229\n",
            "Epoch 33/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0224 - val_accuracy: 0.9175 - val_loss: 0.3185\n",
            "Epoch 34/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9993 - loss: 0.0225 - val_accuracy: 0.9150 - val_loss: 0.3231\n",
            "Epoch 35/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 0.0201 - val_accuracy: 0.9200 - val_loss: 0.3275\n",
            "Epoch 36/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0198 - val_accuracy: 0.9212 - val_loss: 0.3168\n",
            "Epoch 37/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 0.0181 - val_accuracy: 0.9200 - val_loss: 0.3310\n",
            "Epoch 38/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0169 - val_accuracy: 0.9212 - val_loss: 0.3284\n",
            "Epoch 39/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0186 - val_accuracy: 0.9200 - val_loss: 0.3325\n",
            "Epoch 40/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0167 - val_accuracy: 0.9187 - val_loss: 0.3275\n",
            "Epoch 41/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0158 - val_accuracy: 0.9200 - val_loss: 0.3302\n",
            "Epoch 42/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0157 - val_accuracy: 0.9150 - val_loss: 0.3332\n",
            "Epoch 43/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0147 - val_accuracy: 0.9162 - val_loss: 0.3367\n",
            "Epoch 44/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 0.0142 - val_accuracy: 0.9187 - val_loss: 0.3401\n",
            "Epoch 45/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0130 - val_accuracy: 0.9162 - val_loss: 0.3416\n",
            "Epoch 46/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0123 - val_accuracy: 0.9162 - val_loss: 0.3436\n",
            "Epoch 47/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0125 - val_accuracy: 0.9162 - val_loss: 0.3455\n",
            "Epoch 48/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0105 - val_accuracy: 0.9162 - val_loss: 0.3415\n",
            "Epoch 49/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0113 - val_accuracy: 0.9150 - val_loss: 0.3475\n",
            "Epoch 50/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0118 - val_accuracy: 0.9187 - val_loss: 0.3452\n",
            "Epoch 1/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.4055 - loss: 1.8280 - val_accuracy: 0.8413 - val_loss: 0.5735\n",
            "Epoch 2/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8571 - loss: 0.5023 - val_accuracy: 0.8875 - val_loss: 0.4370\n",
            "Epoch 3/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8921 - loss: 0.3652 - val_accuracy: 0.9038 - val_loss: 0.3625\n",
            "Epoch 4/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9108 - loss: 0.3082 - val_accuracy: 0.9150 - val_loss: 0.3379\n",
            "Epoch 5/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9285 - loss: 0.2436 - val_accuracy: 0.9100 - val_loss: 0.3289\n",
            "Epoch 6/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9378 - loss: 0.2260 - val_accuracy: 0.9100 - val_loss: 0.3176\n",
            "Epoch 7/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9454 - loss: 0.2086 - val_accuracy: 0.9187 - val_loss: 0.3043\n",
            "Epoch 8/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9466 - loss: 0.1905 - val_accuracy: 0.9100 - val_loss: 0.3212\n",
            "Epoch 9/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9453 - loss: 0.2005 - val_accuracy: 0.9038 - val_loss: 0.3092\n",
            "Epoch 10/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9552 - loss: 0.1696 - val_accuracy: 0.9162 - val_loss: 0.2951\n",
            "Epoch 11/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9673 - loss: 0.1318 - val_accuracy: 0.9187 - val_loss: 0.3051\n",
            "Epoch 12/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9698 - loss: 0.1271 - val_accuracy: 0.9175 - val_loss: 0.3022\n",
            "Epoch 13/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9681 - loss: 0.1261 - val_accuracy: 0.9112 - val_loss: 0.3036\n",
            "Epoch 14/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9767 - loss: 0.1055 - val_accuracy: 0.9237 - val_loss: 0.2929\n",
            "Epoch 15/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9827 - loss: 0.0917 - val_accuracy: 0.9225 - val_loss: 0.2797\n",
            "Epoch 16/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9860 - loss: 0.0878 - val_accuracy: 0.9212 - val_loss: 0.2842\n",
            "Epoch 17/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9853 - loss: 0.0797 - val_accuracy: 0.9212 - val_loss: 0.2970\n",
            "Epoch 18/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9854 - loss: 0.0810 - val_accuracy: 0.9137 - val_loss: 0.2839\n",
            "Epoch 19/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9875 - loss: 0.0722 - val_accuracy: 0.9162 - val_loss: 0.2955\n",
            "Epoch 20/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9922 - loss: 0.0650 - val_accuracy: 0.9162 - val_loss: 0.2898\n",
            "Epoch 21/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9959 - loss: 0.0513 - val_accuracy: 0.9150 - val_loss: 0.2929\n",
            "Epoch 22/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9963 - loss: 0.0508 - val_accuracy: 0.9187 - val_loss: 0.2906\n",
            "Epoch 23/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9931 - loss: 0.0479 - val_accuracy: 0.9187 - val_loss: 0.2954\n",
            "Epoch 24/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9954 - loss: 0.0432 - val_accuracy: 0.9162 - val_loss: 0.3026\n",
            "Epoch 25/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9968 - loss: 0.0373 - val_accuracy: 0.9150 - val_loss: 0.3004\n",
            "Epoch 26/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9976 - loss: 0.0401 - val_accuracy: 0.9212 - val_loss: 0.3043\n",
            "Epoch 27/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 0.0331 - val_accuracy: 0.9162 - val_loss: 0.3054\n",
            "Epoch 28/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0302 - val_accuracy: 0.9150 - val_loss: 0.3104\n",
            "Epoch 29/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9984 - loss: 0.0326 - val_accuracy: 0.9175 - val_loss: 0.3031\n",
            "Epoch 30/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9989 - loss: 0.0268 - val_accuracy: 0.9212 - val_loss: 0.3045\n",
            "Epoch 31/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0261 - val_accuracy: 0.9212 - val_loss: 0.3170\n",
            "Epoch 32/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0270 - val_accuracy: 0.9212 - val_loss: 0.3038\n",
            "Epoch 33/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0217 - val_accuracy: 0.9187 - val_loss: 0.3101\n",
            "Epoch 34/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9996 - loss: 0.0197 - val_accuracy: 0.9162 - val_loss: 0.3164\n",
            "Epoch 35/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0195 - val_accuracy: 0.9150 - val_loss: 0.3207\n",
            "Epoch 36/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9996 - loss: 0.0191 - val_accuracy: 0.9150 - val_loss: 0.3180\n",
            "Epoch 37/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9998 - loss: 0.0174 - val_accuracy: 0.9162 - val_loss: 0.3241\n",
            "Epoch 38/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9985 - loss: 0.0182 - val_accuracy: 0.9175 - val_loss: 0.3186\n",
            "Epoch 39/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 0.0170 - val_accuracy: 0.9187 - val_loss: 0.3277\n",
            "Epoch 40/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0166 - val_accuracy: 0.9175 - val_loss: 0.3174\n",
            "Epoch 41/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0147 - val_accuracy: 0.9187 - val_loss: 0.3232\n",
            "Epoch 42/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 0.0137 - val_accuracy: 0.9175 - val_loss: 0.3265\n",
            "Epoch 43/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0145 - val_accuracy: 0.9175 - val_loss: 0.3217\n",
            "Epoch 44/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0128 - val_accuracy: 0.9175 - val_loss: 0.3277\n",
            "Epoch 45/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0119 - val_accuracy: 0.9150 - val_loss: 0.3293\n",
            "Epoch 46/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0113 - val_accuracy: 0.9175 - val_loss: 0.3329\n",
            "Epoch 47/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0108 - val_accuracy: 0.9175 - val_loss: 0.3308\n",
            "Epoch 48/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0097 - val_accuracy: 0.9162 - val_loss: 0.3327\n",
            "Epoch 49/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0101 - val_accuracy: 0.9175 - val_loss: 0.3357\n",
            "Epoch 50/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0100 - val_accuracy: 0.9175 - val_loss: 0.3354\n",
            "Epoch 1/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.4212 - loss: 1.8073 - val_accuracy: 0.8050 - val_loss: 0.6503\n",
            "Epoch 2/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8468 - loss: 0.4835 - val_accuracy: 0.8662 - val_loss: 0.4462\n",
            "Epoch 3/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8893 - loss: 0.3794 - val_accuracy: 0.8988 - val_loss: 0.3608\n",
            "Epoch 4/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9202 - loss: 0.2927 - val_accuracy: 0.9025 - val_loss: 0.3447\n",
            "Epoch 5/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9282 - loss: 0.2495 - val_accuracy: 0.9000 - val_loss: 0.3625\n",
            "Epoch 6/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9315 - loss: 0.2454 - val_accuracy: 0.9150 - val_loss: 0.3172\n",
            "Epoch 7/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9365 - loss: 0.2177 - val_accuracy: 0.9175 - val_loss: 0.2937\n",
            "Epoch 8/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9485 - loss: 0.1800 - val_accuracy: 0.9162 - val_loss: 0.2951\n",
            "Epoch 9/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9556 - loss: 0.1642 - val_accuracy: 0.9013 - val_loss: 0.3228\n",
            "Epoch 10/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9527 - loss: 0.1602 - val_accuracy: 0.9125 - val_loss: 0.2910\n",
            "Epoch 11/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9579 - loss: 0.1456 - val_accuracy: 0.9162 - val_loss: 0.2987\n",
            "Epoch 12/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9684 - loss: 0.1328 - val_accuracy: 0.9137 - val_loss: 0.3050\n",
            "Epoch 13/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9692 - loss: 0.1288 - val_accuracy: 0.9162 - val_loss: 0.3010\n",
            "Epoch 14/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9740 - loss: 0.1045 - val_accuracy: 0.9225 - val_loss: 0.2848\n",
            "Epoch 15/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0949 - val_accuracy: 0.9212 - val_loss: 0.2895\n",
            "Epoch 16/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9787 - loss: 0.0921 - val_accuracy: 0.9250 - val_loss: 0.2865\n",
            "Epoch 17/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9836 - loss: 0.0801 - val_accuracy: 0.9200 - val_loss: 0.2799\n",
            "Epoch 18/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9895 - loss: 0.0620 - val_accuracy: 0.9225 - val_loss: 0.2906\n",
            "Epoch 19/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9890 - loss: 0.0772 - val_accuracy: 0.9137 - val_loss: 0.3020\n",
            "Epoch 20/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9895 - loss: 0.0671 - val_accuracy: 0.9200 - val_loss: 0.3058\n",
            "Epoch 21/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9924 - loss: 0.0556 - val_accuracy: 0.9112 - val_loss: 0.2987\n",
            "Epoch 22/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9954 - loss: 0.0517 - val_accuracy: 0.9275 - val_loss: 0.2862\n",
            "Epoch 23/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9941 - loss: 0.0512 - val_accuracy: 0.9250 - val_loss: 0.2848\n",
            "Epoch 24/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9954 - loss: 0.0464 - val_accuracy: 0.9237 - val_loss: 0.2990\n",
            "Epoch 25/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9969 - loss: 0.0391 - val_accuracy: 0.9162 - val_loss: 0.3132\n",
            "Epoch 26/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9963 - loss: 0.0366 - val_accuracy: 0.9237 - val_loss: 0.2876\n",
            "Epoch 27/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9972 - loss: 0.0348 - val_accuracy: 0.9225 - val_loss: 0.2899\n",
            "Epoch 28/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9985 - loss: 0.0320 - val_accuracy: 0.9275 - val_loss: 0.2961\n",
            "Epoch 29/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9958 - loss: 0.0331 - val_accuracy: 0.9237 - val_loss: 0.2943\n",
            "Epoch 30/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9984 - loss: 0.0288 - val_accuracy: 0.9187 - val_loss: 0.3034\n",
            "Epoch 31/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0231 - val_accuracy: 0.9225 - val_loss: 0.3009\n",
            "Epoch 32/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0229 - val_accuracy: 0.9237 - val_loss: 0.3008\n",
            "Epoch 33/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9987 - loss: 0.0234 - val_accuracy: 0.9250 - val_loss: 0.3035\n",
            "Epoch 34/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0260 - val_accuracy: 0.9287 - val_loss: 0.3010\n",
            "Epoch 35/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0235 - val_accuracy: 0.9225 - val_loss: 0.3049\n",
            "Epoch 36/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0192 - val_accuracy: 0.9237 - val_loss: 0.3034\n",
            "Epoch 37/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0185 - val_accuracy: 0.9250 - val_loss: 0.3104\n",
            "Epoch 38/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0184 - val_accuracy: 0.9250 - val_loss: 0.3073\n",
            "Epoch 39/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0164 - val_accuracy: 0.9200 - val_loss: 0.3162\n",
            "Epoch 40/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0162 - val_accuracy: 0.9287 - val_loss: 0.3110\n",
            "Epoch 41/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0143 - val_accuracy: 0.9275 - val_loss: 0.3083\n",
            "Epoch 42/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0140 - val_accuracy: 0.9250 - val_loss: 0.3147\n",
            "Epoch 43/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0141 - val_accuracy: 0.9300 - val_loss: 0.3094\n",
            "Epoch 44/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0124 - val_accuracy: 0.9262 - val_loss: 0.3151\n",
            "Epoch 45/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0126 - val_accuracy: 0.9275 - val_loss: 0.3165\n",
            "Epoch 46/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0124 - val_accuracy: 0.9250 - val_loss: 0.3166\n",
            "Epoch 47/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0122 - val_accuracy: 0.9262 - val_loss: 0.3190\n",
            "Epoch 48/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0108 - val_accuracy: 0.9262 - val_loss: 0.3197\n",
            "Epoch 49/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0104 - val_accuracy: 0.9275 - val_loss: 0.3212\n",
            "Epoch 50/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0106 - val_accuracy: 0.9287 - val_loss: 0.3215\n",
            "Epoch 1/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.3903 - loss: 1.8437 - val_accuracy: 0.8300 - val_loss: 0.6027\n",
            "Epoch 2/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8608 - loss: 0.4768 - val_accuracy: 0.8875 - val_loss: 0.3965\n",
            "Epoch 3/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8916 - loss: 0.3446 - val_accuracy: 0.9000 - val_loss: 0.3488\n",
            "Epoch 4/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9234 - loss: 0.2682 - val_accuracy: 0.9050 - val_loss: 0.3192\n",
            "Epoch 5/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9331 - loss: 0.2340 - val_accuracy: 0.9087 - val_loss: 0.3195\n",
            "Epoch 6/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9406 - loss: 0.2151 - val_accuracy: 0.9175 - val_loss: 0.3017\n",
            "Epoch 7/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9459 - loss: 0.1896 - val_accuracy: 0.9150 - val_loss: 0.2951\n",
            "Epoch 8/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9522 - loss: 0.1766 - val_accuracy: 0.9187 - val_loss: 0.2763\n",
            "Epoch 9/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9593 - loss: 0.1448 - val_accuracy: 0.9262 - val_loss: 0.2731\n",
            "Epoch 10/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9664 - loss: 0.1416 - val_accuracy: 0.9175 - val_loss: 0.2796\n",
            "Epoch 11/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9689 - loss: 0.1297 - val_accuracy: 0.9137 - val_loss: 0.2781\n",
            "Epoch 12/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9764 - loss: 0.1146 - val_accuracy: 0.9187 - val_loss: 0.2670\n",
            "Epoch 13/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9747 - loss: 0.1099 - val_accuracy: 0.9137 - val_loss: 0.2828\n",
            "Epoch 14/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9759 - loss: 0.0958 - val_accuracy: 0.9162 - val_loss: 0.2714\n",
            "Epoch 15/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9840 - loss: 0.0847 - val_accuracy: 0.9187 - val_loss: 0.2762\n",
            "Epoch 16/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9825 - loss: 0.0841 - val_accuracy: 0.9237 - val_loss: 0.2718\n",
            "Epoch 17/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9878 - loss: 0.0717 - val_accuracy: 0.9137 - val_loss: 0.2838\n",
            "Epoch 18/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9913 - loss: 0.0559 - val_accuracy: 0.9162 - val_loss: 0.2751\n",
            "Epoch 19/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9891 - loss: 0.0571 - val_accuracy: 0.9250 - val_loss: 0.2715\n",
            "Epoch 20/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9915 - loss: 0.0561 - val_accuracy: 0.9225 - val_loss: 0.2836\n",
            "Epoch 21/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9940 - loss: 0.0457 - val_accuracy: 0.9225 - val_loss: 0.2711\n",
            "Epoch 22/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9955 - loss: 0.0437 - val_accuracy: 0.9150 - val_loss: 0.2710\n",
            "Epoch 23/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9987 - loss: 0.0369 - val_accuracy: 0.9150 - val_loss: 0.2750\n",
            "Epoch 24/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9964 - loss: 0.0418 - val_accuracy: 0.9187 - val_loss: 0.2827\n",
            "Epoch 25/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0316 - val_accuracy: 0.9250 - val_loss: 0.2872\n",
            "Epoch 26/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0298 - val_accuracy: 0.9187 - val_loss: 0.2818\n",
            "Epoch 27/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0287 - val_accuracy: 0.9225 - val_loss: 0.2818\n",
            "Epoch 28/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0305 - val_accuracy: 0.9237 - val_loss: 0.2827\n",
            "Epoch 29/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0246 - val_accuracy: 0.9237 - val_loss: 0.2961\n",
            "Epoch 30/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0240 - val_accuracy: 0.9150 - val_loss: 0.2918\n",
            "Epoch 31/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0192 - val_accuracy: 0.9162 - val_loss: 0.2999\n",
            "Epoch 32/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0214 - val_accuracy: 0.9137 - val_loss: 0.2902\n",
            "Epoch 33/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0199 - val_accuracy: 0.9212 - val_loss: 0.2955\n",
            "Epoch 34/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0175 - val_accuracy: 0.9225 - val_loss: 0.2922\n",
            "Epoch 35/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0171 - val_accuracy: 0.9212 - val_loss: 0.2959\n",
            "Epoch 36/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0173 - val_accuracy: 0.9225 - val_loss: 0.2995\n",
            "Epoch 37/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0146 - val_accuracy: 0.9225 - val_loss: 0.3006\n",
            "Epoch 38/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0148 - val_accuracy: 0.9200 - val_loss: 0.2992\n",
            "Epoch 39/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0134 - val_accuracy: 0.9237 - val_loss: 0.3047\n",
            "Epoch 40/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0133 - val_accuracy: 0.9212 - val_loss: 0.3093\n",
            "Epoch 41/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0125 - val_accuracy: 0.9200 - val_loss: 0.3025\n",
            "Epoch 42/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0119 - val_accuracy: 0.9175 - val_loss: 0.3000\n",
            "Epoch 43/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0109 - val_accuracy: 0.9200 - val_loss: 0.3107\n",
            "Epoch 44/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0102 - val_accuracy: 0.9225 - val_loss: 0.3116\n",
            "Epoch 45/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0102 - val_accuracy: 0.9200 - val_loss: 0.3089\n",
            "Epoch 46/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0103 - val_accuracy: 0.9212 - val_loss: 0.3097\n",
            "Epoch 47/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0093 - val_accuracy: 0.9200 - val_loss: 0.3112\n",
            "Epoch 48/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0088 - val_accuracy: 0.9187 - val_loss: 0.3087\n",
            "Epoch 49/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0094 - val_accuracy: 0.9187 - val_loss: 0.3160\n",
            "Epoch 50/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0088 - val_accuracy: 0.9187 - val_loss: 0.3140\n",
            "Epoch 1/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.4021 - loss: 1.8646 - val_accuracy: 0.8313 - val_loss: 0.5896\n",
            "Epoch 2/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8676 - loss: 0.4666 - val_accuracy: 0.8875 - val_loss: 0.4089\n",
            "Epoch 3/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9092 - loss: 0.3336 - val_accuracy: 0.8975 - val_loss: 0.3871\n",
            "Epoch 4/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9162 - loss: 0.2954 - val_accuracy: 0.9175 - val_loss: 0.3335\n",
            "Epoch 5/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9295 - loss: 0.2593 - val_accuracy: 0.8938 - val_loss: 0.3779\n",
            "Epoch 6/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9361 - loss: 0.2435 - val_accuracy: 0.9212 - val_loss: 0.3080\n",
            "Epoch 7/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9491 - loss: 0.1842 - val_accuracy: 0.9075 - val_loss: 0.3293\n",
            "Epoch 8/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9573 - loss: 0.1805 - val_accuracy: 0.9200 - val_loss: 0.2986\n",
            "Epoch 9/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9594 - loss: 0.1580 - val_accuracy: 0.9125 - val_loss: 0.3131\n",
            "Epoch 10/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9613 - loss: 0.1479 - val_accuracy: 0.9175 - val_loss: 0.2907\n",
            "Epoch 11/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9727 - loss: 0.1113 - val_accuracy: 0.9200 - val_loss: 0.2830\n",
            "Epoch 12/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9731 - loss: 0.1190 - val_accuracy: 0.9150 - val_loss: 0.2946\n",
            "Epoch 13/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9779 - loss: 0.1043 - val_accuracy: 0.9187 - val_loss: 0.2896\n",
            "Epoch 14/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9778 - loss: 0.0963 - val_accuracy: 0.9125 - val_loss: 0.3080\n",
            "Epoch 15/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9769 - loss: 0.0972 - val_accuracy: 0.9112 - val_loss: 0.3007\n",
            "Epoch 16/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9829 - loss: 0.0826 - val_accuracy: 0.9150 - val_loss: 0.2935\n",
            "Epoch 17/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9858 - loss: 0.0746 - val_accuracy: 0.9187 - val_loss: 0.2845\n",
            "Epoch 18/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9927 - loss: 0.0524 - val_accuracy: 0.9112 - val_loss: 0.3026\n",
            "Epoch 19/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9908 - loss: 0.0587 - val_accuracy: 0.9162 - val_loss: 0.2936\n",
            "Epoch 20/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9951 - loss: 0.0459 - val_accuracy: 0.9175 - val_loss: 0.2974\n",
            "Epoch 21/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9947 - loss: 0.0486 - val_accuracy: 0.9137 - val_loss: 0.2929\n",
            "Epoch 22/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9961 - loss: 0.0404 - val_accuracy: 0.9150 - val_loss: 0.3041\n",
            "Epoch 23/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9954 - loss: 0.0423 - val_accuracy: 0.9125 - val_loss: 0.3026\n",
            "Epoch 24/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9965 - loss: 0.0349 - val_accuracy: 0.9162 - val_loss: 0.2976\n",
            "Epoch 25/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9953 - loss: 0.0355 - val_accuracy: 0.9112 - val_loss: 0.3108\n",
            "Epoch 26/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9975 - loss: 0.0301 - val_accuracy: 0.9112 - val_loss: 0.3063\n",
            "Epoch 27/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9983 - loss: 0.0307 - val_accuracy: 0.9137 - val_loss: 0.3109\n",
            "Epoch 28/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9981 - loss: 0.0267 - val_accuracy: 0.9125 - val_loss: 0.3171\n",
            "Epoch 29/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 0.0235 - val_accuracy: 0.9125 - val_loss: 0.3113\n",
            "Epoch 30/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0235 - val_accuracy: 0.9162 - val_loss: 0.3118\n",
            "Epoch 31/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0219 - val_accuracy: 0.9162 - val_loss: 0.3198\n",
            "Epoch 32/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0217 - val_accuracy: 0.9175 - val_loss: 0.3175\n",
            "Epoch 33/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 0.0178 - val_accuracy: 0.9137 - val_loss: 0.3274\n",
            "Epoch 34/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9995 - loss: 0.0184 - val_accuracy: 0.9125 - val_loss: 0.3242\n",
            "Epoch 35/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0166 - val_accuracy: 0.9150 - val_loss: 0.3244\n",
            "Epoch 36/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 0.0151 - val_accuracy: 0.9162 - val_loss: 0.3233\n",
            "Epoch 37/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0146 - val_accuracy: 0.9162 - val_loss: 0.3233\n",
            "Epoch 38/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0146 - val_accuracy: 0.9162 - val_loss: 0.3275\n",
            "Epoch 39/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0129 - val_accuracy: 0.9175 - val_loss: 0.3287\n",
            "Epoch 40/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0111 - val_accuracy: 0.9187 - val_loss: 0.3314\n",
            "Epoch 41/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0124 - val_accuracy: 0.9175 - val_loss: 0.3335\n",
            "Epoch 42/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0114 - val_accuracy: 0.9125 - val_loss: 0.3376\n",
            "Epoch 43/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0117 - val_accuracy: 0.9175 - val_loss: 0.3365\n",
            "Epoch 44/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0108 - val_accuracy: 0.9162 - val_loss: 0.3381\n",
            "Epoch 45/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0096 - val_accuracy: 0.9150 - val_loss: 0.3409\n",
            "Epoch 46/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0101 - val_accuracy: 0.9137 - val_loss: 0.3379\n",
            "Epoch 47/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0093 - val_accuracy: 0.9150 - val_loss: 0.3371\n",
            "Epoch 48/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0092 - val_accuracy: 0.9125 - val_loss: 0.3402\n",
            "Epoch 49/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0093 - val_accuracy: 0.9162 - val_loss: 0.3458\n",
            "Epoch 50/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0089 - val_accuracy: 0.9150 - val_loss: 0.3448\n",
            "Epoch 1/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.4130 - loss: 1.8368 - val_accuracy: 0.8313 - val_loss: 0.6097\n",
            "Epoch 2/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8596 - loss: 0.4904 - val_accuracy: 0.8875 - val_loss: 0.3914\n",
            "Epoch 3/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9055 - loss: 0.3322 - val_accuracy: 0.8950 - val_loss: 0.3607\n",
            "Epoch 4/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9222 - loss: 0.2703 - val_accuracy: 0.9112 - val_loss: 0.3221\n",
            "Epoch 5/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9349 - loss: 0.2357 - val_accuracy: 0.9162 - val_loss: 0.3143\n",
            "Epoch 6/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9382 - loss: 0.2180 - val_accuracy: 0.9025 - val_loss: 0.3244\n",
            "Epoch 7/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9508 - loss: 0.1951 - val_accuracy: 0.9187 - val_loss: 0.2958\n",
            "Epoch 8/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9568 - loss: 0.1701 - val_accuracy: 0.9000 - val_loss: 0.3275\n",
            "Epoch 9/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9639 - loss: 0.1441 - val_accuracy: 0.9212 - val_loss: 0.2860\n",
            "Epoch 10/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9746 - loss: 0.1227 - val_accuracy: 0.9162 - val_loss: 0.2853\n",
            "Epoch 11/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9684 - loss: 0.1225 - val_accuracy: 0.9100 - val_loss: 0.2911\n",
            "Epoch 12/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9725 - loss: 0.1161 - val_accuracy: 0.9175 - val_loss: 0.3008\n",
            "Epoch 13/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9811 - loss: 0.0930 - val_accuracy: 0.9162 - val_loss: 0.3058\n",
            "Epoch 14/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9821 - loss: 0.0953 - val_accuracy: 0.9225 - val_loss: 0.2813\n",
            "Epoch 15/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9861 - loss: 0.0818 - val_accuracy: 0.9200 - val_loss: 0.2859\n",
            "Epoch 16/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9881 - loss: 0.0716 - val_accuracy: 0.9125 - val_loss: 0.3013\n",
            "Epoch 17/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9851 - loss: 0.0765 - val_accuracy: 0.9112 - val_loss: 0.2877\n",
            "Epoch 18/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9910 - loss: 0.0649 - val_accuracy: 0.9112 - val_loss: 0.3171\n",
            "Epoch 19/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9903 - loss: 0.0567 - val_accuracy: 0.9125 - val_loss: 0.2968\n",
            "Epoch 20/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9913 - loss: 0.0557 - val_accuracy: 0.9162 - val_loss: 0.2979\n",
            "Epoch 21/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9908 - loss: 0.0533 - val_accuracy: 0.9137 - val_loss: 0.2910\n",
            "Epoch 22/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9956 - loss: 0.0391 - val_accuracy: 0.9175 - val_loss: 0.3114\n",
            "Epoch 23/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9966 - loss: 0.0386 - val_accuracy: 0.9137 - val_loss: 0.2950\n",
            "Epoch 24/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9966 - loss: 0.0368 - val_accuracy: 0.9162 - val_loss: 0.3028\n",
            "Epoch 25/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9964 - loss: 0.0339 - val_accuracy: 0.9162 - val_loss: 0.2960\n",
            "Epoch 26/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9982 - loss: 0.0337 - val_accuracy: 0.9162 - val_loss: 0.3026\n",
            "Epoch 27/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9986 - loss: 0.0306 - val_accuracy: 0.9175 - val_loss: 0.2991\n",
            "Epoch 28/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9995 - loss: 0.0263 - val_accuracy: 0.9175 - val_loss: 0.2998\n",
            "Epoch 29/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0241 - val_accuracy: 0.9175 - val_loss: 0.3122\n",
            "Epoch 30/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0226 - val_accuracy: 0.9162 - val_loss: 0.3091\n",
            "Epoch 31/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0232 - val_accuracy: 0.9150 - val_loss: 0.3104\n",
            "Epoch 32/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9989 - loss: 0.0231 - val_accuracy: 0.9187 - val_loss: 0.3110\n",
            "Epoch 33/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0183 - val_accuracy: 0.9162 - val_loss: 0.3109\n",
            "Epoch 34/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0181 - val_accuracy: 0.9162 - val_loss: 0.3181\n",
            "Epoch 35/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0170 - val_accuracy: 0.9175 - val_loss: 0.3173\n",
            "Epoch 36/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 0.0172 - val_accuracy: 0.9150 - val_loss: 0.3189\n",
            "Epoch 37/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0158 - val_accuracy: 0.9175 - val_loss: 0.3191\n",
            "Epoch 38/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0144 - val_accuracy: 0.9175 - val_loss: 0.3284\n",
            "Epoch 39/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0147 - val_accuracy: 0.9125 - val_loss: 0.3225\n",
            "Epoch 40/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0132 - val_accuracy: 0.9125 - val_loss: 0.3263\n",
            "Epoch 41/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0135 - val_accuracy: 0.9137 - val_loss: 0.3249\n",
            "Epoch 42/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0112 - val_accuracy: 0.9150 - val_loss: 0.3279\n",
            "Epoch 43/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0118 - val_accuracy: 0.9150 - val_loss: 0.3285\n",
            "Epoch 44/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0109 - val_accuracy: 0.9150 - val_loss: 0.3307\n",
            "Epoch 45/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0108 - val_accuracy: 0.9137 - val_loss: 0.3322\n",
            "Epoch 46/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0097 - val_accuracy: 0.9175 - val_loss: 0.3311\n",
            "Epoch 47/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0093 - val_accuracy: 0.9137 - val_loss: 0.3354\n",
            "Epoch 48/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0089 - val_accuracy: 0.9125 - val_loss: 0.3353\n",
            "Epoch 49/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0085 - val_accuracy: 0.9162 - val_loss: 0.3324\n",
            "Epoch 50/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0086 - val_accuracy: 0.9125 - val_loss: 0.3355\n",
            "Epoch 1/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.3941 - loss: 1.8499 - val_accuracy: 0.8313 - val_loss: 0.5775\n",
            "Epoch 2/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8546 - loss: 0.5055 - val_accuracy: 0.8825 - val_loss: 0.4143\n",
            "Epoch 3/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9016 - loss: 0.3323 - val_accuracy: 0.8875 - val_loss: 0.3865\n",
            "Epoch 4/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9262 - loss: 0.2860 - val_accuracy: 0.9013 - val_loss: 0.3349\n",
            "Epoch 5/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9309 - loss: 0.2578 - val_accuracy: 0.9112 - val_loss: 0.3407\n",
            "Epoch 6/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9360 - loss: 0.2410 - val_accuracy: 0.9075 - val_loss: 0.3061\n",
            "Epoch 7/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9487 - loss: 0.1901 - val_accuracy: 0.9150 - val_loss: 0.2941\n",
            "Epoch 8/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9536 - loss: 0.1753 - val_accuracy: 0.9125 - val_loss: 0.2941\n",
            "Epoch 9/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9593 - loss: 0.1541 - val_accuracy: 0.9162 - val_loss: 0.2846\n",
            "Epoch 10/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9649 - loss: 0.1343 - val_accuracy: 0.9162 - val_loss: 0.2861\n",
            "Epoch 11/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9648 - loss: 0.1328 - val_accuracy: 0.9187 - val_loss: 0.2704\n",
            "Epoch 12/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9697 - loss: 0.1239 - val_accuracy: 0.9100 - val_loss: 0.2861\n",
            "Epoch 13/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9682 - loss: 0.1311 - val_accuracy: 0.9200 - val_loss: 0.2775\n",
            "Epoch 14/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0947 - val_accuracy: 0.9175 - val_loss: 0.2797\n",
            "Epoch 15/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9852 - loss: 0.0797 - val_accuracy: 0.9125 - val_loss: 0.2769\n",
            "Epoch 16/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9820 - loss: 0.0810 - val_accuracy: 0.9212 - val_loss: 0.2675\n",
            "Epoch 17/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9889 - loss: 0.0662 - val_accuracy: 0.9162 - val_loss: 0.2763\n",
            "Epoch 18/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9895 - loss: 0.0660 - val_accuracy: 0.9200 - val_loss: 0.2709\n",
            "Epoch 19/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9891 - loss: 0.0673 - val_accuracy: 0.9225 - val_loss: 0.2693\n",
            "Epoch 20/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9916 - loss: 0.0599 - val_accuracy: 0.9162 - val_loss: 0.2769\n",
            "Epoch 21/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9919 - loss: 0.0566 - val_accuracy: 0.9212 - val_loss: 0.2799\n",
            "Epoch 22/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9943 - loss: 0.0456 - val_accuracy: 0.9175 - val_loss: 0.2839\n",
            "Epoch 23/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9951 - loss: 0.0422 - val_accuracy: 0.9200 - val_loss: 0.2810\n",
            "Epoch 24/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9966 - loss: 0.0412 - val_accuracy: 0.9137 - val_loss: 0.2754\n",
            "Epoch 25/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9972 - loss: 0.0343 - val_accuracy: 0.9175 - val_loss: 0.2805\n",
            "Epoch 26/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9964 - loss: 0.0347 - val_accuracy: 0.9212 - val_loss: 0.2824\n",
            "Epoch 27/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9983 - loss: 0.0301 - val_accuracy: 0.9225 - val_loss: 0.2802\n",
            "Epoch 28/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9967 - loss: 0.0318 - val_accuracy: 0.9212 - val_loss: 0.2801\n",
            "Epoch 29/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9989 - loss: 0.0267 - val_accuracy: 0.9225 - val_loss: 0.2803\n",
            "Epoch 30/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0240 - val_accuracy: 0.9212 - val_loss: 0.2849\n",
            "Epoch 31/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0235 - val_accuracy: 0.9225 - val_loss: 0.2866\n",
            "Epoch 32/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0228 - val_accuracy: 0.9212 - val_loss: 0.2884\n",
            "Epoch 33/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0198 - val_accuracy: 0.9175 - val_loss: 0.2918\n",
            "Epoch 34/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 0.0190 - val_accuracy: 0.9212 - val_loss: 0.2974\n",
            "Epoch 35/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0199 - val_accuracy: 0.9175 - val_loss: 0.2906\n",
            "Epoch 36/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0164 - val_accuracy: 0.9212 - val_loss: 0.2949\n",
            "Epoch 37/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9997 - loss: 0.0162 - val_accuracy: 0.9237 - val_loss: 0.2939\n",
            "Epoch 38/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 0.0157 - val_accuracy: 0.9200 - val_loss: 0.3009\n",
            "Epoch 39/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 0.0135 - val_accuracy: 0.9212 - val_loss: 0.2971\n",
            "Epoch 40/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0140 - val_accuracy: 0.9237 - val_loss: 0.3004\n",
            "Epoch 41/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0136 - val_accuracy: 0.9237 - val_loss: 0.2978\n",
            "Epoch 42/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0128 - val_accuracy: 0.9212 - val_loss: 0.3015\n",
            "Epoch 43/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0121 - val_accuracy: 0.9237 - val_loss: 0.3023\n",
            "Epoch 44/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0112 - val_accuracy: 0.9212 - val_loss: 0.3029\n",
            "Epoch 45/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0109 - val_accuracy: 0.9187 - val_loss: 0.3052\n",
            "Epoch 46/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0101 - val_accuracy: 0.9225 - val_loss: 0.3050\n",
            "Epoch 47/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0099 - val_accuracy: 0.9200 - val_loss: 0.3076\n",
            "Epoch 48/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0098 - val_accuracy: 0.9225 - val_loss: 0.3084\n",
            "Epoch 49/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0093 - val_accuracy: 0.9212 - val_loss: 0.3103\n",
            "Epoch 50/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0090 - val_accuracy: 0.9200 - val_loss: 0.3091\n",
            "Epoch 1/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.3962 - loss: 1.8727 - val_accuracy: 0.8163 - val_loss: 0.6358\n",
            "Epoch 2/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8469 - loss: 0.4996 - val_accuracy: 0.8763 - val_loss: 0.4254\n",
            "Epoch 3/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8935 - loss: 0.3647 - val_accuracy: 0.9013 - val_loss: 0.3709\n",
            "Epoch 4/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9189 - loss: 0.2925 - val_accuracy: 0.8975 - val_loss: 0.3571\n",
            "Epoch 5/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9233 - loss: 0.2638 - val_accuracy: 0.9100 - val_loss: 0.3134\n",
            "Epoch 6/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9404 - loss: 0.2291 - val_accuracy: 0.9050 - val_loss: 0.3168\n",
            "Epoch 7/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9471 - loss: 0.2034 - val_accuracy: 0.9150 - val_loss: 0.2885\n",
            "Epoch 8/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9525 - loss: 0.1677 - val_accuracy: 0.9162 - val_loss: 0.3048\n",
            "Epoch 9/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9567 - loss: 0.1614 - val_accuracy: 0.9087 - val_loss: 0.2973\n",
            "Epoch 10/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9567 - loss: 0.1530 - val_accuracy: 0.9062 - val_loss: 0.2925\n",
            "Epoch 11/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9653 - loss: 0.1371 - val_accuracy: 0.9150 - val_loss: 0.2899\n",
            "Epoch 12/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9725 - loss: 0.1079 - val_accuracy: 0.9050 - val_loss: 0.2933\n",
            "Epoch 13/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9752 - loss: 0.1237 - val_accuracy: 0.9150 - val_loss: 0.2803\n",
            "Epoch 14/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9778 - loss: 0.0927 - val_accuracy: 0.9087 - val_loss: 0.3025\n",
            "Epoch 15/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9779 - loss: 0.0987 - val_accuracy: 0.9137 - val_loss: 0.2970\n",
            "Epoch 16/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9841 - loss: 0.0769 - val_accuracy: 0.9137 - val_loss: 0.3006\n",
            "Epoch 17/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9827 - loss: 0.0810 - val_accuracy: 0.9150 - val_loss: 0.2789\n",
            "Epoch 18/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9885 - loss: 0.0755 - val_accuracy: 0.9100 - val_loss: 0.2995\n",
            "Epoch 19/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9901 - loss: 0.0639 - val_accuracy: 0.9087 - val_loss: 0.3011\n",
            "Epoch 20/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9889 - loss: 0.0630 - val_accuracy: 0.9112 - val_loss: 0.2967\n",
            "Epoch 21/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9924 - loss: 0.0593 - val_accuracy: 0.9125 - val_loss: 0.3010\n",
            "Epoch 22/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9960 - loss: 0.0497 - val_accuracy: 0.9162 - val_loss: 0.2983\n",
            "Epoch 23/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9954 - loss: 0.0413 - val_accuracy: 0.9050 - val_loss: 0.3040\n",
            "Epoch 24/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9971 - loss: 0.0414 - val_accuracy: 0.9112 - val_loss: 0.3066\n",
            "Epoch 25/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9967 - loss: 0.0395 - val_accuracy: 0.9137 - val_loss: 0.2974\n",
            "Epoch 26/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9970 - loss: 0.0403 - val_accuracy: 0.9112 - val_loss: 0.3087\n",
            "Epoch 27/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9970 - loss: 0.0396 - val_accuracy: 0.9075 - val_loss: 0.3095\n",
            "Epoch 28/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 0.0299 - val_accuracy: 0.9112 - val_loss: 0.3134\n",
            "Epoch 29/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0268 - val_accuracy: 0.9087 - val_loss: 0.3099\n",
            "Epoch 30/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0256 - val_accuracy: 0.9100 - val_loss: 0.3258\n",
            "Epoch 31/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9980 - loss: 0.0316 - val_accuracy: 0.9087 - val_loss: 0.3267\n",
            "Epoch 32/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 0.0204 - val_accuracy: 0.9050 - val_loss: 0.3273\n",
            "Epoch 33/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0202 - val_accuracy: 0.9112 - val_loss: 0.3285\n",
            "Epoch 34/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0215 - val_accuracy: 0.9112 - val_loss: 0.3283\n",
            "Epoch 35/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0200 - val_accuracy: 0.9087 - val_loss: 0.3253\n",
            "Epoch 36/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0190 - val_accuracy: 0.9075 - val_loss: 0.3204\n",
            "Epoch 37/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0181 - val_accuracy: 0.9075 - val_loss: 0.3229\n",
            "Epoch 38/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0165 - val_accuracy: 0.9112 - val_loss: 0.3239\n",
            "Epoch 39/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 0.0162 - val_accuracy: 0.9100 - val_loss: 0.3300\n",
            "Epoch 40/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0148 - val_accuracy: 0.9075 - val_loss: 0.3277\n",
            "Epoch 41/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0146 - val_accuracy: 0.9112 - val_loss: 0.3298\n",
            "Epoch 42/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0123 - val_accuracy: 0.9087 - val_loss: 0.3291\n",
            "Epoch 43/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0133 - val_accuracy: 0.9137 - val_loss: 0.3322\n",
            "Epoch 44/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0119 - val_accuracy: 0.9087 - val_loss: 0.3327\n",
            "Epoch 45/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0109 - val_accuracy: 0.9125 - val_loss: 0.3346\n",
            "Epoch 46/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0114 - val_accuracy: 0.9125 - val_loss: 0.3326\n",
            "Epoch 47/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0107 - val_accuracy: 0.9125 - val_loss: 0.3382\n",
            "Epoch 48/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0108 - val_accuracy: 0.9112 - val_loss: 0.3380\n",
            "Epoch 49/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0101 - val_accuracy: 0.9112 - val_loss: 0.3399\n",
            "Epoch 50/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0095 - val_accuracy: 0.9100 - val_loss: 0.3445\n",
            "Epoch 1/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.3861 - loss: 1.8484 - val_accuracy: 0.8300 - val_loss: 0.5904\n",
            "Epoch 2/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8530 - loss: 0.4966 - val_accuracy: 0.8838 - val_loss: 0.4145\n",
            "Epoch 3/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8984 - loss: 0.3581 - val_accuracy: 0.9050 - val_loss: 0.3495\n",
            "Epoch 4/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9182 - loss: 0.3079 - val_accuracy: 0.9087 - val_loss: 0.3485\n",
            "Epoch 5/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9224 - loss: 0.2659 - val_accuracy: 0.9062 - val_loss: 0.3270\n",
            "Epoch 6/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9389 - loss: 0.2252 - val_accuracy: 0.9075 - val_loss: 0.3247\n",
            "Epoch 7/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9408 - loss: 0.2096 - val_accuracy: 0.9075 - val_loss: 0.3282\n",
            "Epoch 8/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9560 - loss: 0.1776 - val_accuracy: 0.9200 - val_loss: 0.3020\n",
            "Epoch 9/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9617 - loss: 0.1496 - val_accuracy: 0.9200 - val_loss: 0.3031\n",
            "Epoch 10/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9609 - loss: 0.1422 - val_accuracy: 0.9125 - val_loss: 0.3079\n",
            "Epoch 11/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9663 - loss: 0.1369 - val_accuracy: 0.9200 - val_loss: 0.2827\n",
            "Epoch 12/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9726 - loss: 0.1138 - val_accuracy: 0.9150 - val_loss: 0.2989\n",
            "Epoch 13/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9812 - loss: 0.0969 - val_accuracy: 0.9162 - val_loss: 0.2914\n",
            "Epoch 14/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9807 - loss: 0.0976 - val_accuracy: 0.9162 - val_loss: 0.2929\n",
            "Epoch 15/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9811 - loss: 0.0901 - val_accuracy: 0.9137 - val_loss: 0.2942\n",
            "Epoch 16/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9874 - loss: 0.0741 - val_accuracy: 0.9162 - val_loss: 0.3004\n",
            "Epoch 17/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9905 - loss: 0.0737 - val_accuracy: 0.9150 - val_loss: 0.2919\n",
            "Epoch 18/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9900 - loss: 0.0591 - val_accuracy: 0.9162 - val_loss: 0.3025\n",
            "Epoch 19/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9880 - loss: 0.0615 - val_accuracy: 0.9150 - val_loss: 0.3043\n",
            "Epoch 20/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9943 - loss: 0.0494 - val_accuracy: 0.9225 - val_loss: 0.2896\n",
            "Epoch 21/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9918 - loss: 0.0529 - val_accuracy: 0.9175 - val_loss: 0.3139\n",
            "Epoch 22/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9953 - loss: 0.0459 - val_accuracy: 0.9187 - val_loss: 0.3032\n",
            "Epoch 23/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9969 - loss: 0.0392 - val_accuracy: 0.9187 - val_loss: 0.3049\n",
            "Epoch 24/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9976 - loss: 0.0409 - val_accuracy: 0.9162 - val_loss: 0.3090\n",
            "Epoch 25/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9977 - loss: 0.0362 - val_accuracy: 0.9162 - val_loss: 0.3205\n",
            "Epoch 26/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9986 - loss: 0.0321 - val_accuracy: 0.9125 - val_loss: 0.3133\n",
            "Epoch 27/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0284 - val_accuracy: 0.9212 - val_loss: 0.3074\n",
            "Epoch 28/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9986 - loss: 0.0291 - val_accuracy: 0.9250 - val_loss: 0.3073\n",
            "Epoch 29/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0258 - val_accuracy: 0.9187 - val_loss: 0.3177\n",
            "Epoch 30/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9984 - loss: 0.0292 - val_accuracy: 0.9150 - val_loss: 0.3201\n",
            "Epoch 31/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 0.0266 - val_accuracy: 0.9212 - val_loss: 0.3177\n",
            "Epoch 32/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0228 - val_accuracy: 0.9162 - val_loss: 0.3204\n",
            "Epoch 33/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0204 - val_accuracy: 0.9200 - val_loss: 0.3229\n",
            "Epoch 34/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0185 - val_accuracy: 0.9175 - val_loss: 0.3133\n",
            "Epoch 35/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 0.0185 - val_accuracy: 0.9187 - val_loss: 0.3297\n",
            "Epoch 36/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0182 - val_accuracy: 0.9187 - val_loss: 0.3277\n",
            "Epoch 37/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0159 - val_accuracy: 0.9212 - val_loss: 0.3223\n",
            "Epoch 38/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0139 - val_accuracy: 0.9212 - val_loss: 0.3253\n",
            "Epoch 39/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0138 - val_accuracy: 0.9162 - val_loss: 0.3237\n",
            "Epoch 40/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 0.0124 - val_accuracy: 0.9175 - val_loss: 0.3316\n",
            "Epoch 41/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9998 - loss: 0.0127 - val_accuracy: 0.9175 - val_loss: 0.3336\n",
            "Epoch 42/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0127 - val_accuracy: 0.9200 - val_loss: 0.3302\n",
            "Epoch 43/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 0.0127 - val_accuracy: 0.9200 - val_loss: 0.3337\n",
            "Epoch 44/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0116 - val_accuracy: 0.9175 - val_loss: 0.3396\n",
            "Epoch 45/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0116 - val_accuracy: 0.9187 - val_loss: 0.3356\n",
            "Epoch 46/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0106 - val_accuracy: 0.9175 - val_loss: 0.3356\n",
            "Epoch 47/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0097 - val_accuracy: 0.9187 - val_loss: 0.3362\n",
            "Epoch 48/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0090 - val_accuracy: 0.9162 - val_loss: 0.3365\n",
            "Epoch 49/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0100 - val_accuracy: 0.9187 - val_loss: 0.3391\n",
            "Epoch 50/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0083 - val_accuracy: 0.9212 - val_loss: 0.3402\n",
            "Epoch 1/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.4049 - loss: 1.8510 - val_accuracy: 0.8250 - val_loss: 0.5766\n",
            "Epoch 2/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8569 - loss: 0.4996 - val_accuracy: 0.8775 - val_loss: 0.4170\n",
            "Epoch 3/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8959 - loss: 0.3636 - val_accuracy: 0.9100 - val_loss: 0.3364\n",
            "Epoch 4/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9191 - loss: 0.2917 - val_accuracy: 0.9125 - val_loss: 0.3338\n",
            "Epoch 5/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9178 - loss: 0.2739 - val_accuracy: 0.9137 - val_loss: 0.3245\n",
            "Epoch 6/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9444 - loss: 0.2169 - val_accuracy: 0.9187 - val_loss: 0.3198\n",
            "Epoch 7/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9447 - loss: 0.2018 - val_accuracy: 0.9237 - val_loss: 0.2947\n",
            "Epoch 8/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9466 - loss: 0.1865 - val_accuracy: 0.9150 - val_loss: 0.2939\n",
            "Epoch 9/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9641 - loss: 0.1506 - val_accuracy: 0.9200 - val_loss: 0.2918\n",
            "Epoch 10/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9674 - loss: 0.1297 - val_accuracy: 0.9225 - val_loss: 0.2832\n",
            "Epoch 11/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9719 - loss: 0.1201 - val_accuracy: 0.9212 - val_loss: 0.2773\n",
            "Epoch 12/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9664 - loss: 0.1309 - val_accuracy: 0.9225 - val_loss: 0.2742\n",
            "Epoch 13/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9762 - loss: 0.1000 - val_accuracy: 0.9237 - val_loss: 0.2691\n",
            "Epoch 14/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9833 - loss: 0.0830 - val_accuracy: 0.9237 - val_loss: 0.2726\n",
            "Epoch 15/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9862 - loss: 0.0781 - val_accuracy: 0.9212 - val_loss: 0.2684\n",
            "Epoch 16/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9862 - loss: 0.0799 - val_accuracy: 0.9200 - val_loss: 0.2749\n",
            "Epoch 17/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9864 - loss: 0.0791 - val_accuracy: 0.9237 - val_loss: 0.2732\n",
            "Epoch 18/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9900 - loss: 0.0624 - val_accuracy: 0.9287 - val_loss: 0.2794\n",
            "Epoch 19/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9933 - loss: 0.0537 - val_accuracy: 0.9225 - val_loss: 0.2734\n",
            "Epoch 20/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9940 - loss: 0.0461 - val_accuracy: 0.9250 - val_loss: 0.2717\n",
            "Epoch 21/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9959 - loss: 0.0465 - val_accuracy: 0.9262 - val_loss: 0.2736\n",
            "Epoch 22/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9935 - loss: 0.0490 - val_accuracy: 0.9250 - val_loss: 0.2760\n",
            "Epoch 23/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9977 - loss: 0.0423 - val_accuracy: 0.9275 - val_loss: 0.2745\n",
            "Epoch 24/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9977 - loss: 0.0355 - val_accuracy: 0.9250 - val_loss: 0.2752\n",
            "Epoch 25/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9952 - loss: 0.0374 - val_accuracy: 0.9250 - val_loss: 0.2807\n",
            "Epoch 26/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9986 - loss: 0.0296 - val_accuracy: 0.9275 - val_loss: 0.2804\n",
            "Epoch 27/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0277 - val_accuracy: 0.9275 - val_loss: 0.2797\n",
            "Epoch 28/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0251 - val_accuracy: 0.9287 - val_loss: 0.2853\n",
            "Epoch 29/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 0.0221 - val_accuracy: 0.9225 - val_loss: 0.2864\n",
            "Epoch 30/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0222 - val_accuracy: 0.9275 - val_loss: 0.2804\n",
            "Epoch 31/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0241 - val_accuracy: 0.9212 - val_loss: 0.2889\n",
            "Epoch 32/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0224 - val_accuracy: 0.9262 - val_loss: 0.2911\n",
            "Epoch 33/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9986 - loss: 0.0226 - val_accuracy: 0.9262 - val_loss: 0.2827\n",
            "Epoch 34/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9997 - loss: 0.0181 - val_accuracy: 0.9287 - val_loss: 0.2848\n",
            "Epoch 35/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0162 - val_accuracy: 0.9287 - val_loss: 0.2917\n",
            "Epoch 36/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 0.0161 - val_accuracy: 0.9300 - val_loss: 0.2972\n",
            "Epoch 37/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.0159 - val_accuracy: 0.9250 - val_loss: 0.2951\n",
            "Epoch 38/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 0.0140 - val_accuracy: 0.9275 - val_loss: 0.2986\n",
            "Epoch 39/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0142 - val_accuracy: 0.9262 - val_loss: 0.2950\n",
            "Epoch 40/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0145 - val_accuracy: 0.9287 - val_loss: 0.2923\n",
            "Epoch 41/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0126 - val_accuracy: 0.9262 - val_loss: 0.2965\n",
            "Epoch 42/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0113 - val_accuracy: 0.9250 - val_loss: 0.2988\n",
            "Epoch 43/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0111 - val_accuracy: 0.9262 - val_loss: 0.3002\n",
            "Epoch 44/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0109 - val_accuracy: 0.9287 - val_loss: 0.3039\n",
            "Epoch 45/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0111 - val_accuracy: 0.9287 - val_loss: 0.2986\n",
            "Epoch 46/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0096 - val_accuracy: 0.9250 - val_loss: 0.3029\n",
            "Epoch 47/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0100 - val_accuracy: 0.9262 - val_loss: 0.3001\n",
            "Epoch 48/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0091 - val_accuracy: 0.9275 - val_loss: 0.3019\n",
            "Epoch 49/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0095 - val_accuracy: 0.9250 - val_loss: 0.3065\n",
            "Epoch 50/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0088 - val_accuracy: 0.9262 - val_loss: 0.3031\n",
            "Epoch 1/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.4155 - loss: 1.8112 - val_accuracy: 0.8475 - val_loss: 0.5356\n",
            "Epoch 2/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8516 - loss: 0.4623 - val_accuracy: 0.8850 - val_loss: 0.4079\n",
            "Epoch 3/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9073 - loss: 0.3140 - val_accuracy: 0.9025 - val_loss: 0.3485\n",
            "Epoch 4/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9183 - loss: 0.2828 - val_accuracy: 0.9100 - val_loss: 0.3214\n",
            "Epoch 5/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9296 - loss: 0.2314 - val_accuracy: 0.9137 - val_loss: 0.3037\n",
            "Epoch 6/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9476 - loss: 0.1965 - val_accuracy: 0.9175 - val_loss: 0.2928\n",
            "Epoch 7/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9444 - loss: 0.2066 - val_accuracy: 0.9212 - val_loss: 0.3020\n",
            "Epoch 8/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9515 - loss: 0.1795 - val_accuracy: 0.9212 - val_loss: 0.2674\n",
            "Epoch 9/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9611 - loss: 0.1487 - val_accuracy: 0.9137 - val_loss: 0.3082\n",
            "Epoch 10/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9655 - loss: 0.1317 - val_accuracy: 0.9262 - val_loss: 0.2722\n",
            "Epoch 11/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9678 - loss: 0.1343 - val_accuracy: 0.9150 - val_loss: 0.2824\n",
            "Epoch 12/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9769 - loss: 0.1090 - val_accuracy: 0.9225 - val_loss: 0.2630\n",
            "Epoch 13/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9793 - loss: 0.0996 - val_accuracy: 0.9212 - val_loss: 0.2668\n",
            "Epoch 14/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9813 - loss: 0.0868 - val_accuracy: 0.9225 - val_loss: 0.2691\n",
            "Epoch 15/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9850 - loss: 0.0774 - val_accuracy: 0.9150 - val_loss: 0.2724\n",
            "Epoch 16/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9868 - loss: 0.0677 - val_accuracy: 0.9200 - val_loss: 0.2720\n",
            "Epoch 17/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9847 - loss: 0.0696 - val_accuracy: 0.9100 - val_loss: 0.2861\n",
            "Epoch 18/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9914 - loss: 0.0639 - val_accuracy: 0.9250 - val_loss: 0.2604\n",
            "Epoch 19/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9913 - loss: 0.0583 - val_accuracy: 0.9212 - val_loss: 0.2679\n",
            "Epoch 20/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9950 - loss: 0.0486 - val_accuracy: 0.9237 - val_loss: 0.2799\n",
            "Epoch 21/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9958 - loss: 0.0426 - val_accuracy: 0.9212 - val_loss: 0.2811\n",
            "Epoch 22/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9965 - loss: 0.0418 - val_accuracy: 0.9175 - val_loss: 0.2737\n",
            "Epoch 23/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9963 - loss: 0.0409 - val_accuracy: 0.9187 - val_loss: 0.2709\n",
            "Epoch 24/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9980 - loss: 0.0328 - val_accuracy: 0.9175 - val_loss: 0.2748\n",
            "Epoch 25/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 0.0287 - val_accuracy: 0.9237 - val_loss: 0.2768\n",
            "Epoch 26/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 0.0291 - val_accuracy: 0.9212 - val_loss: 0.2709\n",
            "Epoch 27/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9987 - loss: 0.0273 - val_accuracy: 0.9237 - val_loss: 0.2677\n",
            "Epoch 28/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0253 - val_accuracy: 0.9262 - val_loss: 0.2718\n",
            "Epoch 29/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0218 - val_accuracy: 0.9212 - val_loss: 0.2802\n",
            "Epoch 30/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0228 - val_accuracy: 0.9212 - val_loss: 0.2798\n",
            "Epoch 31/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0231 - val_accuracy: 0.9312 - val_loss: 0.2772\n",
            "Epoch 32/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0211 - val_accuracy: 0.9237 - val_loss: 0.2800\n",
            "Epoch 33/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0175 - val_accuracy: 0.9212 - val_loss: 0.2855\n",
            "Epoch 34/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0177 - val_accuracy: 0.9212 - val_loss: 0.2850\n",
            "Epoch 35/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0172 - val_accuracy: 0.9225 - val_loss: 0.2944\n",
            "Epoch 36/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 0.0174 - val_accuracy: 0.9187 - val_loss: 0.3019\n",
            "Epoch 37/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0177 - val_accuracy: 0.9237 - val_loss: 0.2869\n",
            "Epoch 38/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0143 - val_accuracy: 0.9237 - val_loss: 0.2857\n",
            "Epoch 39/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0134 - val_accuracy: 0.9225 - val_loss: 0.2872\n",
            "Epoch 40/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0135 - val_accuracy: 0.9262 - val_loss: 0.2892\n",
            "Epoch 41/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0126 - val_accuracy: 0.9237 - val_loss: 0.2922\n",
            "Epoch 42/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 0.0124 - val_accuracy: 0.9212 - val_loss: 0.2978\n",
            "Epoch 43/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0109 - val_accuracy: 0.9250 - val_loss: 0.2928\n",
            "Epoch 44/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0113 - val_accuracy: 0.9262 - val_loss: 0.2920\n",
            "Epoch 45/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0101 - val_accuracy: 0.9262 - val_loss: 0.2920\n",
            "Epoch 46/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0096 - val_accuracy: 0.9250 - val_loss: 0.2927\n",
            "Epoch 47/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0105 - val_accuracy: 0.9187 - val_loss: 0.3010\n",
            "Epoch 48/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0091 - val_accuracy: 0.9287 - val_loss: 0.2983\n",
            "Epoch 49/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0088 - val_accuracy: 0.9275 - val_loss: 0.3003\n",
            "Epoch 50/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0086 - val_accuracy: 0.9237 - val_loss: 0.3025\n",
            "Epoch 1/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.4382 - loss: 1.7484 - val_accuracy: 0.8275 - val_loss: 0.5620\n",
            "Epoch 2/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8646 - loss: 0.4525 - val_accuracy: 0.8875 - val_loss: 0.3948\n",
            "Epoch 3/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8978 - loss: 0.3379 - val_accuracy: 0.9075 - val_loss: 0.3594\n",
            "Epoch 4/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9167 - loss: 0.2753 - val_accuracy: 0.9050 - val_loss: 0.3449\n",
            "Epoch 5/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9317 - loss: 0.2290 - val_accuracy: 0.9013 - val_loss: 0.3384\n",
            "Epoch 6/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9468 - loss: 0.1996 - val_accuracy: 0.9062 - val_loss: 0.3189\n",
            "Epoch 7/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9534 - loss: 0.1762 - val_accuracy: 0.9162 - val_loss: 0.2897\n",
            "Epoch 8/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9566 - loss: 0.1585 - val_accuracy: 0.9112 - val_loss: 0.2922\n",
            "Epoch 9/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9654 - loss: 0.1379 - val_accuracy: 0.9212 - val_loss: 0.2774\n",
            "Epoch 10/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9690 - loss: 0.1277 - val_accuracy: 0.9150 - val_loss: 0.2876\n",
            "Epoch 11/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9744 - loss: 0.1134 - val_accuracy: 0.9150 - val_loss: 0.2782\n",
            "Epoch 12/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9736 - loss: 0.1154 - val_accuracy: 0.9200 - val_loss: 0.2811\n",
            "Epoch 13/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9830 - loss: 0.0887 - val_accuracy: 0.9112 - val_loss: 0.2858\n",
            "Epoch 14/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9820 - loss: 0.0891 - val_accuracy: 0.9275 - val_loss: 0.2747\n",
            "Epoch 15/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9846 - loss: 0.0771 - val_accuracy: 0.9237 - val_loss: 0.2657\n",
            "Epoch 16/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9895 - loss: 0.0659 - val_accuracy: 0.9187 - val_loss: 0.2784\n",
            "Epoch 17/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9901 - loss: 0.0657 - val_accuracy: 0.9250 - val_loss: 0.2625\n",
            "Epoch 18/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9893 - loss: 0.0614 - val_accuracy: 0.9200 - val_loss: 0.2754\n",
            "Epoch 19/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9928 - loss: 0.0597 - val_accuracy: 0.9212 - val_loss: 0.2665\n",
            "Epoch 20/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9955 - loss: 0.0452 - val_accuracy: 0.9237 - val_loss: 0.2677\n",
            "Epoch 21/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9937 - loss: 0.0451 - val_accuracy: 0.9237 - val_loss: 0.2680\n",
            "Epoch 22/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9979 - loss: 0.0369 - val_accuracy: 0.9237 - val_loss: 0.2652\n",
            "Epoch 23/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9954 - loss: 0.0386 - val_accuracy: 0.9237 - val_loss: 0.2671\n",
            "Epoch 24/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9989 - loss: 0.0336 - val_accuracy: 0.9212 - val_loss: 0.2787\n",
            "Epoch 25/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9986 - loss: 0.0321 - val_accuracy: 0.9275 - val_loss: 0.2694\n",
            "Epoch 26/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0285 - val_accuracy: 0.9262 - val_loss: 0.2663\n",
            "Epoch 27/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0256 - val_accuracy: 0.9275 - val_loss: 0.2652\n",
            "Epoch 28/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9984 - loss: 0.0303 - val_accuracy: 0.9237 - val_loss: 0.2735\n",
            "Epoch 29/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0209 - val_accuracy: 0.9275 - val_loss: 0.2783\n",
            "Epoch 30/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0219 - val_accuracy: 0.9237 - val_loss: 0.2795\n",
            "Epoch 31/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0194 - val_accuracy: 0.9262 - val_loss: 0.2819\n",
            "Epoch 32/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0203 - val_accuracy: 0.9275 - val_loss: 0.2765\n",
            "Epoch 33/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0169 - val_accuracy: 0.9300 - val_loss: 0.2749\n",
            "Epoch 34/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9996 - loss: 0.0177 - val_accuracy: 0.9312 - val_loss: 0.2767\n",
            "Epoch 35/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0158 - val_accuracy: 0.9262 - val_loss: 0.2830\n",
            "Epoch 36/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0147 - val_accuracy: 0.9275 - val_loss: 0.2767\n",
            "Epoch 37/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 0.0133 - val_accuracy: 0.9250 - val_loss: 0.2857\n",
            "Epoch 38/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0137 - val_accuracy: 0.9287 - val_loss: 0.2866\n",
            "Epoch 39/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 0.0130 - val_accuracy: 0.9287 - val_loss: 0.2850\n",
            "Epoch 40/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 0.0121 - val_accuracy: 0.9275 - val_loss: 0.2897\n",
            "Epoch 41/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0113 - val_accuracy: 0.9300 - val_loss: 0.2804\n",
            "Epoch 42/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0109 - val_accuracy: 0.9275 - val_loss: 0.2874\n",
            "Epoch 43/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0110 - val_accuracy: 0.9275 - val_loss: 0.2902\n",
            "Epoch 44/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0104 - val_accuracy: 0.9300 - val_loss: 0.2841\n",
            "Epoch 45/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0092 - val_accuracy: 0.9300 - val_loss: 0.2883\n",
            "Epoch 46/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0085 - val_accuracy: 0.9300 - val_loss: 0.2872\n",
            "Epoch 47/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0082 - val_accuracy: 0.9312 - val_loss: 0.2876\n",
            "Epoch 48/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0083 - val_accuracy: 0.9287 - val_loss: 0.2866\n",
            "Epoch 49/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0086 - val_accuracy: 0.9325 - val_loss: 0.2874\n",
            "Epoch 50/50\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0083 - val_accuracy: 0.9312 - val_loss: 0.2885\n",
            "    number of parameters  Training Error  Validation Error\n",
            "0                   3190        0.362953          0.679126\n",
            "1                   6370        0.063145          0.619393\n",
            "2                  12730        0.021400          0.416707\n",
            "3                  25450        0.010908          0.362173\n",
            "4                  33400        0.010788          0.345156\n",
            "5                  34990        0.009948          0.335382\n",
            "6                  36580        0.010191          0.321500\n",
            "7                  38170        0.008778          0.314027\n",
            "8                  39760        0.008654          0.344766\n",
            "9                  41350        0.008716          0.335469\n",
            "10                 42940        0.009156          0.309137\n",
            "11                 44530        0.009705          0.344515\n",
            "12                 50890        0.008955          0.340245\n",
            "13                 60430        0.008674          0.303117\n",
            "14                 69970        0.008559          0.302465\n",
            "15                 79510        0.008196          0.288515\n"
          ]
        }
      ],
      "source": [
        "random.seed(321)\n",
        "error = []\n",
        "for num_params in params:\n",
        "    train_error, val_error, num_params = create_model(num_params, train_images, train_labels)\n",
        "    error.append({'number of parameters': num_params, 'Training Error': train_error, 'Validation Error': val_error})\n",
        "\n",
        "#error = pd.DataFrame(columns=['Training Error', 'Validation Error'])\n",
        "error= pd.DataFrame(error)#, columns=['Training Error', 'Validation Error'])\n",
        "print(error)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "jzcF4nbBooqF",
        "outputId": "e2f54d86-7360-41f1-c95a-6e33ae8ac680"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ploting double descent curve\n",
        "number_of_examples = len(train_images)\n",
        "plt.plot(error['number of parameters'], error['Validation Error'], label='Validation Error', marker='o')\n",
        "plt.plot(error['number of parameters'], error['Training Error'], label='Training Error', marker='o')\n",
        "#plt.axvline(number_of_examples, color='black', linestyle='-', linewidth=1, marker='o') # last edited by Jeff, p\n",
        "plt.axvline(number_of_examples * 10, color='black', linestyle='-', linewidth=1, marker='o') # jeff changed this (interpolation threshold)\n",
        "plt.xlabel('Number of Parameters')\n",
        "plt.ylabel('Error')\n",
        "plt.title(f'Training and Validation Error vs. Number of Parameters\\n(Number of Training Examples: {number_of_examples})')\n",
        "plt.legend()\n",
        "plt.ticklabel_format(style='plain', axis='x')\n",
        "plt.ylim(0, 0.6)\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xW6u8rHmVwkw"
      },
      "outputs": [],
      "source": [
        "#kamal\n",
        "# find two models in the two regimes having same score\n",
        "# vary batch_size and claim that after a certain size, it saturates\n",
        "# compare variances for different weight initializations in two regimes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Gut2MArRqiga",
        "outputId": "fdc3cee6-76d6-4c2a-ee7d-065a737a0f2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "50/50 [==============================] - 1s 7ms/step - loss: 1.2749 - accuracy: 0.6369 - val_loss: 0.5589 - val_accuracy: 0.8350\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.8681 - val_loss: 0.4024 - val_accuracy: 0.8875\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.3381 - accuracy: 0.9034 - val_loss: 0.3514 - val_accuracy: 0.9013\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.2838 - accuracy: 0.9172 - val_loss: 0.3254 - val_accuracy: 0.9062\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.2458 - accuracy: 0.9312 - val_loss: 0.3103 - val_accuracy: 0.9187\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.2178 - accuracy: 0.9438 - val_loss: 0.3155 - val_accuracy: 0.9175\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.1953 - accuracy: 0.9453 - val_loss: 0.3024 - val_accuracy: 0.9187\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.1769 - accuracy: 0.9513 - val_loss: 0.3325 - val_accuracy: 0.9087\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.1705 - accuracy: 0.9541 - val_loss: 0.2988 - val_accuracy: 0.9200\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.1495 - accuracy: 0.9603 - val_loss: 0.2797 - val_accuracy: 0.9262\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.1305 - accuracy: 0.9684 - val_loss: 0.2887 - val_accuracy: 0.9212\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.1195 - accuracy: 0.9722 - val_loss: 0.2925 - val_accuracy: 0.9162\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.1080 - accuracy: 0.9756 - val_loss: 0.2771 - val_accuracy: 0.9250\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0992 - accuracy: 0.9759 - val_loss: 0.2809 - val_accuracy: 0.9225\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0891 - accuracy: 0.9809 - val_loss: 0.2909 - val_accuracy: 0.9187\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0902 - accuracy: 0.9791 - val_loss: 0.2828 - val_accuracy: 0.9225\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0743 - accuracy: 0.9866 - val_loss: 0.2839 - val_accuracy: 0.9225\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0728 - accuracy: 0.9869 - val_loss: 0.2802 - val_accuracy: 0.9212\n",
            "Epoch 18: early stopping\n",
            "Number of epochs to convergence: 18\n"
          ]
        }
      ],
      "source": [
        "# Define early stopping criteria\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
        "\n",
        "# Train the model with early stopping\n",
        "num_parameters = 55 # <------------------------------------CHANGE THIS PARAMETER\n",
        "# I propose num_parameters:\n",
        "  # Under-Parameterized: 45\n",
        "  # Over-Parameterized: 55, 64\n",
        "\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),  # Flatten the input images\n",
        "    Dense(num_parameters, activation='relu'),   # Fully connected layer\n",
        "    Dense(10, activation='softmax')  # Output layer with 10 neurons\n",
        "])\n",
        "sgd = SGD(momentum=0.95)\n",
        "model.compile(optimizer=sgd,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images, train_labels,\n",
        "                    epochs=50,\n",
        "                    batch_size=64,\n",
        "                    validation_split=0.2,\n",
        "                    callbacks=[early_stopping])\n",
        "\n",
        "# Determine the number of epochs it took for convergence\n",
        "num_epochs_to_convergence = len(history.history['loss'])\n",
        "print(f'Number of epochs to convergence: {num_epochs_to_convergence}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6VIKz33HvFVM"
      },
      "outputs": [],
      "source": [
        "# Calculating the convergence rate for different batch sizes\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=0)\n",
        "def model_convergence(batch_size):\n",
        "\n",
        "    model1 = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),  # Flatten the input images\n",
        "    Dense(32, activation='relu'),   # --------------------------  I used 45 for underparameterized model\n",
        "    Dense(10, activation='softmax')  # Output layer with 10 neurons\n",
        "    ])\n",
        "    sgd = SGD(momentum=0.95)\n",
        "    model1.compile(optimizer=sgd,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "    history1 = model1.fit(train_images, train_labels,\n",
        "                    epochs=50,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_split=0.2,\n",
        "                    callbacks=[early_stopping],verbose =0)\n",
        "\n",
        "    # Determine the number of epochs it took for convergence\n",
        "    num_epochs_to_convergence1 = len(history1.history['loss'])\n",
        "\n",
        "    model2 = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),  # Flatten the input images\n",
        "    Dense(64, activation='relu'),   # ------------------------ I used 55 for overparameterized model\n",
        "    Dense(10, activation='softmax')  # Output layer with 10 neurons\n",
        "    ])\n",
        "    sgd = SGD(momentum=0.95)\n",
        "    model2.compile(optimizer=sgd,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "    history2 = model2.fit(train_images, train_labels,\n",
        "                    epochs=50,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_split=0.2,\n",
        "                    callbacks=[early_stopping],verbose=0)\n",
        "\n",
        "    # Determine the number of epochs it took for convergence\n",
        "    num_epochs_to_convergence2 = len(history2.history['loss'])\n",
        "\n",
        "\n",
        "    return num_epochs_to_convergence1 , num_epochs_to_convergence2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mFxc9yi4wiiC",
        "outputId": "5aa7c9bc-b194-4e54-a3ce-77eb543dfef5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[2, 4, 8, 16, 32, 64, 128]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_sizes = [2**i for i in range(1,8)]\n",
        "#batch_sizes = [4,48,64,100,128,160,200,256]\n",
        "batch_sizes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QXjuy_vSw3g6"
      },
      "outputs": [],
      "source": [
        "val_pct = 0.2 # percent used for validation\n",
        "num_samples = len(train_images) * (1 - val_pct)\n",
        "epochs = []\n",
        "for i in range(5):\n",
        "    for batch_size in batch_sizes:\n",
        "\n",
        "        x,y = model_convergence(batch_size)\n",
        "        epochs.append({'model1': x*(math.ceil(num_samples/batch_size)), 'model2': y*(math.ceil(num_samples/batch_size)), \"batch size\":batch_size, \"iteration\":i})\n",
        "\n",
        "epochs= pd.DataFrame(epochs)\n",
        "print(epochs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oP-qAekSx8WY"
      },
      "outputs": [],
      "source": [
        "epochs = epochs.groupby('batch size').mean().reset_index()\n",
        "\n",
        "# Plot for Multiple Runs\n",
        "plt.scatter(epochs[\"batch size\"], epochs['model1'], label='Underparameterized model', marker='o')\n",
        "plt.scatter(epochs[\"batch size\"], epochs['model2'], label='Overparameterized model', marker='o')\n",
        "plt.plot(epochs['batch size'], epochs['model1'])\n",
        "plt.plot(epochs['batch size'], epochs['model2'])\n",
        "plt.xlabel('Batch Size')\n",
        "plt.ylabel('Number of Iterations until Convergence')\n",
        "plt.title(\"Number of Iterations vs Batch Size for Underparameterized and Overparameterized regime\")\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nGq2BfFePPe"
      },
      "outputs": [],
      "source": [
        "\n",
        "batch_sizes = [4, 12, 16, 48, 64, 84, 100]\n",
        "num_iter = 2 # number of times to run the same conditions\n",
        "\n",
        "# Average Multiple Runs\n",
        "epochs = []\n",
        "for batch_size in batch_sizes:\n",
        "  for i in range(num_iter):\n",
        "    x,y = model_convergence(batch_size)\n",
        "    epochs.append({'model1': x, 'model2': y, \"batch size\":batch_size})\n",
        "epochs= pd.DataFrame(epochs)\n",
        "print(epochs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZttuHz2AAF5"
      },
      "outputs": [],
      "source": [
        "# Translate Epochs to Iterations\n",
        "\n",
        "val_pct = 0.2 # percent used for validation\n",
        "num_samples = len(train_images) * (1 - val_pct)\n",
        "\n",
        "num_iter = (num_samples / batch_size) * num_epochs\n",
        "model1_num_iter = (num_samples / epochs['batch size']) * epochs['model1']\n",
        "model2_num_iter = (num_samples / epochs['batch size']) * epochs['model2']\n",
        "\n",
        "iter_df = {\n",
        "    'batch size': epochs['batch size'],\n",
        "    'model1': model1_num_iter,\n",
        "    'model2': model2_num_iter\n",
        "}\n",
        "iter_df = pd.DataFrame(iter_df)\n",
        "print(iter_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUAgPf3jz633"
      },
      "outputs": [],
      "source": [
        "# Take Average of Runs\n",
        "iter_summary = iter_df.groupby('batch size').mean().reset_index()\n",
        "\n",
        "# Plot for Multiple Runs\n",
        "plt.scatter(iter_df[\"batch size\"], iter_df['model1'], label='Underparameterized model', marker='o')\n",
        "plt.scatter(iter_df[\"batch size\"], iter_df['model2'], label='Overparameterized model', marker='o')\n",
        "plt.plot(iter_summary['batch size'], iter_summary['model1'])\n",
        "plt.plot(iter_summary['batch size'], iter_summary['model2'])\n",
        "plt.xlabel('Batch Size')\n",
        "plt.ylabel('Number of Iterations until Convergence')\n",
        "plt.title(\"Number of Iterations vs Batch Size for Underparameterized and Overparameterized regime\")\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kaZ1rBW7vnnW"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import Callback\n",
        "\n",
        "class StopAfterIterations(Callback):\n",
        "  # Saves the loss after each batch\n",
        "  # Stops training after t iterations\n",
        "\n",
        "    def __init__(self, max_iterations):\n",
        "        super(StopAfterIterations, self).__init__()\n",
        "        self.max_iterations = max_iterations\n",
        "        self.iterations = 0\n",
        "        self.accuracy = []\n",
        "        self.loss = []\n",
        "\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        self.accuracy.append(logs.get('accuracy'))\n",
        "        self.loss.append(logs.get('loss'))\n",
        "        self.iterations += 1\n",
        "        if self.iterations >= self.max_iterations:\n",
        "            self.model.stop_training = True\n",
        "            print(f\"Stopped training after {self.max_iterations} iterations.\")\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "            self.total_iterations = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XeNfeD8xbZMl"
      },
      "outputs": [],
      "source": [
        "# Instantiate the custom callback\n",
        "batch_sizes = [32,64,128,512,1024,2048]\n",
        "max_iterations=500\n",
        "output_under = np.zeros((max_iterations,len(batch_sizes)+1))\n",
        "column_names = ['Iteration'] + [f'Batch_{batch_size}' for batch_size in batch_sizes]\n",
        "\n",
        "output_over = np.zeros((max_iterations,len(batch_sizes)+1))\n",
        "i=1\n",
        "for batch_size in batch_sizes:\n",
        "    # Under-Parameterized Model\n",
        "    num_parameters = 45\n",
        "    under_model = Sequential([\n",
        "        Flatten(input_shape=(28, 28)),  # Flatten the input images\n",
        "        Dense(num_parameters, activation='relu'),   # Fully connected layer with num_parameters neurons\\renewcommand{\\thesection}{Appendix \\Alph{section}}\n",
        "        Dense(10, activation='softmax')  # Output layer with 10 neurons (one for each class)\n",
        "    ])\n",
        "\n",
        "    # Over-Parameterized Model\n",
        "    num_parameters = 55\n",
        "    over_model = Sequential([\n",
        "        Flatten(input_shape=(28, 28)),  # Flatten the input images\n",
        "        Dense(num_parameters, activation='relu'),   # Fully connected layer with num_parameters neurons\\renewcommand{\\thesection}{Appendix \\Alph{section}}\n",
        "        Dense(10, activation='softmax')  # Output layer with 10 neurons (one for each class)\n",
        "    ])\n",
        "\n",
        "    under_sgd = SGD() # SGD must be defined for both regimes\n",
        "    under_model.compile(optimizer=under_sgd,\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    over_sgd = SGD() # SGD must be defined for both regimes\n",
        "    over_model.compile(optimizer=over_sgd,\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Fit the model and store the training history\n",
        "    under_stop_after_iterations = StopAfterIterations(max_iterations)\n",
        "    under_history = under_model.fit(train_images, train_labels, epochs=max_iterations, batch_size=batch_size, validation_split=0.2, callbacks=[under_stop_after_iterations],verbose=0)\n",
        "    output_under[:,i] = under_stop_after_iterations.loss\n",
        "    over_stop_after_iterations = StopAfterIterations(max_iterations)\n",
        "    over_history = over_model.fit(train_images, train_labels, epochs=max_iterations, batch_size=batch_size, validation_split=0.2, callbacks=[over_stop_after_iterations],verbose=0)\n",
        "    output_over[:,i] = over_stop_after_iterations.loss\n",
        "    i=i+1\n",
        "output_under[:,0] = range(under_stop_after_iterations.iterations)\n",
        "output_over[:,0] = range(over_stop_after_iterations.iterations)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmG-6Pijbc3q"
      },
      "outputs": [],
      "source": [
        "\n",
        "output_under = pd.DataFrame(output_under, columns = column_names)\n",
        "\n",
        "output_over = pd.DataFrame(output_over, columns = column_names)\n",
        "#yy = under_stop_after_iterations.loss\n",
        "\n",
        "for i, column in enumerate(output_under.columns[1:], start=1):\n",
        "    plt.scatter(output_under.iloc[:, 0], output_under.iloc[:, i], alpha=1,label=column, marker='.', linestyle='-')\n",
        "\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')  # Adjust ylabel according to your data\n",
        "plt.title('Loss vs. Iteration for Different Batch Sizes Underparameterized')\n",
        "plt.legend(title='Batch Size')\n",
        "plt.show()\n",
        "\n",
        "\"\"\"\n",
        "xx = range(over_stop_after_iterations.iterations)\n",
        "yy = over_stop_after_iterations.loss\n",
        "plt.scatter(xx, yy, label='Overparameterized model', marker='o')\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "for i, column in enumerate(output_over.columns[1:], start=1):\n",
        "    plt.scatter(output_over.iloc[:, 0], output_over.iloc[:, i], alpha=1,label=column, marker='.', linestyle='-')\n",
        "\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')  # Adjust ylabel according to your data\n",
        "plt.title('Loss vs. Iteration for Different Batch Sizes Overparameterized')\n",
        "plt.legend(title='Batch Size')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYfrBAEIgwm8"
      },
      "outputs": [],
      "source": [
        "plt.scatter(output_over[:,0], output_over[:,1], label='8', alpha=0.5, marker='.', linestyle='-')\n",
        "plt.scatter(output_over[:,0], output_over[:,2], label='128', alpha=0.5, marker='.', linestyle='-')\n",
        "plt.scatter(output_over[:,0], output_over[:,3], label='3200', alpha=0.5, marker='.', linestyle='-')\n",
        "\n",
        "\"\"\"\n",
        "xx = range(over_stop_after_iterations.iterations)\n",
        "yy = over_stop_after_iterations.loss\n",
        "plt.scatter(xx, yy, label='Overparameterized model', marker='o')\n",
        "\"\"\"\n",
        "\n",
        "#plt.plot(iter_summary['batch size'], iter_summary['model1'])\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Loss')\n",
        "plt.title(\"Number of Iterations vs Batch Size for Underparameterized and Overparameterized regime\")\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yoSvCjPFirX3"
      },
      "outputs": [],
      "source": [
        "output_under[350:400,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZYQnAj4nTKj"
      },
      "outputs": [],
      "source": [
        "# Instantiate the custom callback\n",
        "num_train = 3200\n",
        "batch_sizes = [8, 16, 32, 64, 128, 640, num_train]\n",
        "max_iter = 1024\n",
        "output_under = np.zeros((max_iter,len(batch_sizes)+1))\n",
        "column_names = ['Iteration'] + [f'Batch_{batch_size}' for batch_size in batch_sizes]\n",
        "\n",
        "\n",
        "# ========\n",
        "# Fit Data\n",
        "# ========\n",
        "under_lst = [0] * len(batch_sizes)\n",
        "over_lst = [0] * len(batch_sizes)\n",
        "\n",
        "output_over = np.zeros((max_iter,len(batch_sizes)+1))\n",
        "i=0\n",
        "for batch_size in batch_sizes:\n",
        "\n",
        "    # Under-Parameterized Model\n",
        "    num_parameters = 32\n",
        "    under_model = Sequential([\n",
        "        Flatten(input_shape=(28, 28)),  # Flatten the input images\n",
        "        Dense(num_parameters, activation='relu'),\n",
        "        Dense(10, activation='softmax')  #\n",
        "    ])\n",
        "\n",
        "    # Over-Parameterized Model\n",
        "    num_parameters = 64\n",
        "    over_model = Sequential([\n",
        "        Flatten(input_shape=(28, 28)),  # Flatten the input images\n",
        "        Dense(num_parameters, activation='relu'),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    under_sgd = SGD() # SGD must be defined for both regimes\n",
        "    under_model.compile(optimizer=under_sgd,\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    over_sgd = SGD() # SGD must be defined for both regimes\n",
        "    over_model.compile(optimizer=over_sgd,\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # ============================================\n",
        "    # Fit the model and store the training history\n",
        "    # ============================================\n",
        "    batches_per_epoch = int(num_train / batch_size)\n",
        "    num_epochs = math.ceil(max_iter / batches_per_epoch)\n",
        "    start_iter = batches_per_epoch\n",
        "    end_iter = batches_per_epoch * num_epochs + batches_per_epoch\n",
        "\n",
        "    # Underparameterized\n",
        "    under_history = under_model.fit(train_images, train_labels,\n",
        "                        epochs=num_epochs, batch_size=batch_size,\n",
        "                        validation_split=0.2, verbose=0)\n",
        "    under_df = {\n",
        "        't': list(range(start_iter, end_iter, batches_per_epoch)),\n",
        "        'loss': under_history.history['loss']\n",
        "    }\n",
        "    under_lst[i] = pd.DataFrame(under_df)\n",
        "\n",
        "    # Overparameterized\n",
        "    over_history = over_model.fit(train_images, train_labels,\n",
        "                        epochs=num_epochs, batch_size=batch_size,\n",
        "                        validation_split=0.2, verbose=0)\n",
        "    over_df = {\n",
        "        't': list(range(start_iter, end_iter, batches_per_epoch)),\n",
        "        'loss': over_history.history['loss']\n",
        "    }\n",
        "\n",
        "    over_lst[i] = pd.DataFrame(over_df)\n",
        "    i=i+1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOYgT0NeM5o6"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Plot Results (Underparameterized)\n",
        "for i in range(len(batch_sizes)):\n",
        "    plt.plot(under_lst[i]['t'], np.log(under_lst[i]['loss']), alpha=1, label=batch_sizes[i])\n",
        "\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Log Loss')  # Adjust ylabel according to your data\n",
        "plt.title('Loss vs. Iteration for Different Batch Sizes Underparameterized')\n",
        "plt.legend(title='Batch Size')\n",
        "plt.show()\n",
        "\n",
        "# Plot Results (Overparameterized)\n",
        "for i in range(len(batch_sizes)):\n",
        "    plt.plot(over_lst[i]['t'], np.log(over_lst[i]['loss']), alpha=1, label=batch_sizes[i])\n",
        "\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Log Loss')  # Adjust ylabel according to your data\n",
        "plt.title('Loss vs. Iteration for Different Batch Sizes Overparameterized')\n",
        "plt.legend(title='Batch Size')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGfK6KsVulLx"
      },
      "outputs": [],
      "source": [
        "# Get Ratio of Underparameterized / Ovewrparameterized\n",
        "for i in range(5):\n",
        "  print((under_lst[i] / over_lst[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUpQjH6PG7Q_"
      },
      "outputs": [],
      "source": [
        "#cody stuff\n",
        "\n",
        "#define function to grab the norm for the weight matrices\n",
        "def get_model_spectral_norms(model):\n",
        "    norms = []\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, tf.keras.layers.Dense):\n",
        "            weights, biases = layer.get_weights()\n",
        "            singular_values = np.linalg.svd(weights, compute_uv=False)\n",
        "            spectral_norm = np.max(singular_values)\n",
        "            norms.append(spectral_norm)\n",
        "    return norms\n",
        "\n",
        "# Calculate norms of weight matrices for the underparameterized model\n",
        "under_spectral_norms = get_model_spectral_norms(under_model)\n",
        "print(\"Spectral norms of the underparameterized model weight matrices:\")\n",
        "for i, norm in enumerate(under_spectral_norms, 1):\n",
        "    print(f\"Layer {i}: {norm}\")\n",
        "\n",
        "# Calculate norms of weight matrices for the overparameterized model\n",
        "over_spectral_norms = get_model_spectral_norms(over_model)\n",
        "print(\"Spectral norms of the overparameterized model weight matrices:\")\n",
        "for i, norm in enumerate(over_spectral_norms, 1):\n",
        "    print(f\"Layer {i}: {norm}\")\n",
        "\n",
        "\n",
        "# Define function to grab the largest and smallest positive eigenvalues for the weight matrices\n",
        "def get_model_eigenvalues(model):\n",
        "    eigenvalues = []\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, tf.keras.layers.Dense):\n",
        "            weights, _ = layer.get_weights()\n",
        "            singular_values = np.linalg.svd(weights, compute_uv=False)\n",
        "            max_eigenvalue = np.max(singular_values)  # Largest eigenvalue\n",
        "            min_eigenvalue = np.min(singular_values[singular_values > 0]) if np.any(singular_values > 0) else 0  # Smallest positive eigenvalue\n",
        "            eigenvalues.append((max_eigenvalue, min_eigenvalue))\n",
        "    return eigenvalues\n",
        "\n",
        "# Under-parameterized Model (e.g., num_parameters = 45)\n",
        "under_model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(45, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "under_sgd = SGD(momentum=0.95)\n",
        "under_model.compile(optimizer=under_sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# Assume the model is already trained before this call\n",
        "under_eigenvalues = get_model_eigenvalues(under_model)\n",
        "print(\"Eigenvalues of the underparameterized model weight matrices:\")\n",
        "for i, (max_eig, min_eig) in enumerate(under_eigenvalues, 1):\n",
        "    print(f\"Layer {i} - Largest: {max_eig}, Smallest Positive: {min_eig}\")\n",
        "\n",
        "# Over-parameterized Model (e.g., num_parameters = 64)\n",
        "over_model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "over_sgd = SGD(momentum=0.95)\n",
        "over_model.compile(optimizer=over_sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# Assume the model is already trained before this call\n",
        "over_eigenvalues = get_model_eigenvalues(over_model)\n",
        "print(\"Eigenvalues of the overparameterized model weight matrices:\")\n",
        "for i, (max_eig, min_eig) in enumerate(over_eigenvalues, 1):\n",
        "    print(f\"Layer {i} - Largest: {max_eig}, Smallest Positive: {min_eig}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGx4rH5aG8K8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}